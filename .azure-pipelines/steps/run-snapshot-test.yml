parameters:
  - name: 'target'
    type: 'string'

  - name: 'snapshotPrefix'
    type: 'string'
    
  - name: isLinux
    type: boolean
    default: true

  - name: isNoop
    type: boolean
    default: false

  - name: 'apiKey'
    type: string
    default: ''
  
  - name: 'dockerComposePath'
    type: string
    default: 'docker-compose'
  
  - name: 'testAgentTarget'
    type: string
    default: ''

steps:
- template: ./clean-docker-containers.yml

- bash: |
    echo "##vso[task.setvariable variable=TOKEN]$(System.JobId)"
    echo "##vso[task.setvariable variable=START_ENDPOINT]/test/session/start?test_session_token=$(System.JobId)"
    echo "##vso[task.setvariable variable=TRACE_DUMP_ENDPOINT]/test/session/traces?test_session_token=$(System.JobId)"
    echo "##vso[task.setvariable variable=STATS_DUMP_ENDPOINT]/test/session/stats?test_session_token=$(System.JobId)"
    echo "##vso[task.setvariable variable=REQUESTS_DUMP_ENDPOINT]/test/session/requests?test_session_token=$(System.JobId)"
    
    if [ "$(publishFramework)" = "netcoreapp2.1" ]; then
      snapshotfile="${{ parameters.snapshotPrefix }}_snapshots_2_1"
    else
      snapshotfile="${{ parameters.snapshotPrefix }}_snapshots"
    fi
    
    echo "##vso[task.setvariable variable=VERIFY_ENDPOINT]/test/session/snapshot?test_session_token=$(System.JobId)&file=/snapshots/$snapshotfile"
  displayName: Set endpoints

- ${{ if eq(parameters.isLinux, true) }}:
  - bash: |
      testAgentTarget="${{ parameters.testAgentTarget }}"
      testAgentTarget="${testAgentTarget:-test-agent}"
      echo "##vso[task.setvariable variable=CURL_COMMAND]/usr/bin/curl"
      echo "##vso[task.setvariable variable=TEST_AGENT_TARGET]${testAgentTarget}"
      echo "##vso[task.setvariable variable=START_TEST_AGENT_TARGET]start-${testAgentTarget}"
      echo "##vso[task.setvariable variable=COMPOSE_PATH]docker-compose.yml"
    displayName: Set env-specific variables

  - script: |
      mkdir -p artifacts/build_data/snapshots
      mkdir -p artifacts/build_data/logs
      mkdir -p artifacts/build_data/dumps
      # make sure that the container have enough rights to write in this folder
      sudo chmod -R 777 artifacts/build_data/ || true
    displayName: create test data directories
- ${{ else }}:
  - bash: |
      testAgentTarget="${{ parameters.testAgentTarget }}"
      testAgentTarget="${testAgentTarget:-test-agent.windows}"
      echo "##vso[task.setvariable variable=CURL_COMMAND]curl"
      echo "##vso[task.setvariable variable=TEST_AGENT_TARGET]${testAgentTarget}"
      echo "##vso[task.setvariable variable=START_TEST_AGENT_TARGET]start-${testAgentTarget}"
      echo "##vso[task.setvariable variable=COMPOSE_PATH]docker-compose.windows.yml"
    displayName: Set env-specific  variables

- bash: |
    set -euo pipefail
    P="${DDC_PROJECT:-ddtrace_$(Build.BuildNumber)}"
    DC='${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p '"$P"

    echo "Using compose project: $P"

    # --- HARD RESET (safe to run every time; very helpful on retries) ---
    # Tear down project resources (containers, networks, named/anon volumes, orphans)
    $DC down -v --remove-orphans || true
    # Remove any stopped leftovers Compose knows about
    $DC rm -fsv || true
    # Belt-and-suspenders: remove any stragglers with the project label
    docker ps -aq --filter "label=com.docker.compose.project=$P" | xargs -r docker rm -f || true
    docker network ls -q --filter "label=com.docker.compose.project=$P" | xargs -r docker network rm || true
    docker volume ls -q --filter "label=com.docker.compose.project=$P" | xargs -r docker volume rm -f || true
    # Give containerd a moment to release any stale shims
    sleep 2
    # --------------------------------------------------------------------

    # 1) Start the agent fresh (force-recreate to avoid reusing any half-state)
    $DC up -d --force-recreate --renew-anon-volumes $(TEST_AGENT_TARGET)

    # 2) Block until it’s listening on 8126 (your wait container)
    $DC run --rm $(START_TEST_AGENT_TARGET)
  env:
    dockerTag: $(dockerTag)
    DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}
  displayName: docker-compose run start-test-agent
  retryCountOnTaskFailure: 3

- script: |
    echo "Starting snapshot session"
    ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) exec -T $(TEST_AGENT_TARGET) $(CURL_COMMAND) --fail "http://localhost:8126$(START_ENDPOINT)"
  displayName: start snapshot session
  env:
    DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}

- bash: |
    # We explicitly set the DD_PROFILING_ENABLED=1 flag here, because we want to ensure that profiling is enabled for this
    # test, but _not_ for the crash tracking test. For some scenarios (e.g. chiseled tests) we can't set env vars directly
    # in the container, so we explicitly set this once here because it needs to change between the two tests.
    ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) run -e dockerTag=$(dockerTag) -e DD_PROFILING_ENABLED=1 -e PROFILER_IS_NOT_REQUIRED=${{ parameters.isNoop }} ${{ parameters.target }}
  env:
    dockerTag: $(dockerTag)
    DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}
  displayName: ${{ parameters.dockerComposePath }} run ${{ parameters.target }}
  timeoutInMinutes: 15

- script: |
    echo "Dumping traces"
    ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) exec -T $(TEST_AGENT_TARGET) $(CURL_COMMAND) -o /debug_snapshots/${{ parameters.snapshotPrefix }}_traces.json "http://localhost:8126$(TRACE_DUMP_ENDPOINT)"
    
    echo "Dumping stats"
    ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) exec -T $(TEST_AGENT_TARGET) $(CURL_COMMAND) -o /debug_snapshots/${{ parameters.snapshotPrefix }}_stats.json "http://localhost:8126$(STATS_DUMP_ENDPOINT)"
    
    echo "Dumping all requests"
    ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) exec -T $(TEST_AGENT_TARGET) $(CURL_COMMAND) -o /debug_snapshots/${{ parameters.snapshotPrefix }}_requests.json "http://localhost:8126$(REQUESTS_DUMP_ENDPOINT)"
  displayName: dump snapshots
  env:
    DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}

- ${{ if and(eq(parameters.isLinux, true), eq(parameters.isNoop, false)) }}:
  - bash: |
      echo "Verifying snapshot session (fail on mis-match)"
      ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) exec -T $(TEST_AGENT_TARGET) $(CURL_COMMAND) --fail-with-body "http://localhost:8126$(VERIFY_ENDPOINT)"
    displayName: check snapshots
    env:
      DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}
- ${{ elseif and(eq(parameters.isLinux, true), eq(parameters.isNoop, true)) }}:
    - bash: |
        path="/debug_snapshots/${{ parameters.snapshotPrefix }}_requests.json"
        echo "Verifying noop snapshot session (requests should be empty)"
        if [ -s $path ]; then
          echo "$path is not empty"
          if [ "$(cat "$path" | tr -d '\n')" = "[]" ]; then
            echo "$path contains no requests[]"
          else
            echo "The file unexpectedly contained requests"
          exit 1
          fi
        else
          echo "$path was empty"
        fi
      displayName: check noop snapshots
- ${{ else }}:
  - bash: |
      echo "Verifying snapshot session (fail on mis-match)"
      ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) exec -T $(TEST_AGENT_TARGET) $(CURL_COMMAND) --fail-with-body "http://localhost:8126$(VERIFY_ENDPOINT)"
    displayName: check snapshots
    env:
      DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}

- script: ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) logs $(TEST_AGENT_TARGET)
  displayName: dump docker-compose logs for $(TEST_AGENT_TARGET)
  env:
    DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}
  condition: succeededOrFailed()
  continueOnError: true

- script: ${{ parameters.dockerComposePath }} -f $(COMPOSE_PATH) -p ddtrace_$(Build.BuildNumber) down
  displayName: docker-compose stop services
  env:
    DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}
  condition: succeededOrFailed()
  continueOnError: true

# Run crash tests
- ${{ if and(eq(parameters.isLinux, true), eq(parameters.isNoop, false)) }}:
  - bash: |
      set -u -o pipefail

      TMPLOG="$(mktemp)"
      COMPOSE="${{ parameters.dockerComposePath }}"
      PROJ="ddtrace_$(Build.BuildNumber)"

      # Build the compose run command; -T disables TTY (prevents buffering/hangs)
      CMD=( "$COMPOSE" -f "$(COMPOSE_PATH)" -p "$PROJ" run --rm -T \
            -e dockerTag="$(dockerTag)" \
            -e DD_PROFILING_ENABLED=0 \
            -e CRASH_APP_ON_STARTUP=1 \
            -e DD_CRASHTRACKING_INTERNAL_LOG_TO_CONSOLE=1 \
            -e COMPlus_DbgEnableMiniDump=0 \
            ${{ parameters.target }} )

      echo "Running: ${CMD[*]}"

      # Bound execution to avoid indefinite hangs; force line-buffered stdout/stderr
      # (stdbuf is available on Alpine-based agents; if not, remove it)
      if ! timeout 240s stdbuf -oL -eL "${CMD[@]}" 2>&1 | tee "$TMPLOG" ; then
        # Don't fail the step yet—crash is expected; just record exit code.
        rc=${PIPESTATUS[0]}
        echo "compose run exited with code $rc (non-zero is expected in a crash test)."
      fi

      expected="The crash may have been caused by automatic instrumentation"
      if grep -Fq "$expected" "$TMPLOG"; then
        echo "✅ Correctly found evidence of crash detection"
      else
        echo "❌ Did not find required evidence of crash detection"
        # Helpful diagnostics before failing
        "$COMPOSE" -f "$(COMPOSE_PATH)" -p "$PROJ" ps || true
        "$COMPOSE" -f "$(COMPOSE_PATH)" -p "$PROJ" logs --no-color || true
        # Fail the task
        exit 1
      fi

      # Always cleanup to avoid orphans impacting subsequent runs
      "$COMPOSE" -f "$(COMPOSE_PATH)" -p "$PROJ" down -v --remove-orphans || true
    env:
      dockerTag: $(dockerTag)
      DD_LOGGER_DD_API_KEY: ${{ parameters.apiKey }}
    displayName: Check logs for evidence of crash output
    # This job sometimes hangs, and when it does, we lose all the logs, so explicitly end it early instead
    # and retry instead. It should be very unlikely to hang on both trys, and if it does, we should probably
    # investigate the cause of the hang further.
    timeoutInMinutes: 5
    retryCountOnTaskFailure: 2
    condition: and(succeeded(), eq(variables['runCrashTest'], 'true'))

- ${{ if eq(parameters.isLinux, true) }}:
    - script: |
        sudo chmod -R 644 artifacts/build_data/dumps/* || true
      displayName: Make dumps uploadable to AzDo
      condition: succeededOrFailed()

- script: |
    docker network prune -f
  displayName: Clean up docker networks
  condition: succeededOrFailed()
  continueOnError: true

- template: ./make-artifacts-uploadable.yml