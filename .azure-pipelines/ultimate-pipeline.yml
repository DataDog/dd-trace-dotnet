trigger:
  branches:
    include:
      - master
      - release/*
      - hotfix/*
    exclude:
      - refs/pull/*/head
      - refs/tags/*
  paths:
    exclude:
      - .azure-pipelines/noop-pipeline.yml
      - .azure-pipelines/monitoring.yml
      - .github/
      - docs/
      - tracer/README.MD
      - tracer/dependabot/
      - tracer/tools/PipelineMonitor
      - LICENSE
      - LICENSE-3rdparty.csv
      - NOTICE
      - .vsconfig
# The following is a list of shared asset locations.
# This is the config for the Tracer CI pipeline,
# so we are excluding shared assets that are not currently used by the Tracer.
# We make this list granular, rather than catch-all, on purpose.
# It makes it easier to selectively remove items from the list, once the Tracer starts using them.
#     - The Managed Loader:
      - shared/samples/Datadog.AutoInstrumentation.ManagedLoader.Demo/
      - shared/src/managed-lib/ManagedLoader/
#     - Dynamic Bindings for DiagnosticSource:
      - shared/samples/Datadog.DynamicDiagnosticSourceBindings.Demo/
      - shared/src/managed-lib/DynamicDiagnosticSourceBindings/
#     - Logging damo samples:
      - shared/samples/Datadog.Logging.Demo/
#     - Managed utility APIs (may be used transitively):
      - shared/src/managed-src/Datadog.Collections/
      - shared/src/managed-src/Datadog.Util/
#     - Managed Logging APIs (may be used transitively):
      - shared/src/managed-src/Datadog.Logging.Emission/
      - shared/src/managed-src/Datadog.Logging.Composition/
      - shared/src/managed-src/Datadog.Logging/
#     - Fmt lib:
      - shared/src/native-lib/fmt_x64-windows-static/
      - shared/src/native-lib/fmt_x86-windows-static/
#     - Spdlob lib:
      - shared/src/native-lib/spdlog/
#     - Mics common native sources:
      - shared/src/native-src/

pr:
  branches:
    include:
      - '*' # default
  paths:
    exclude:
      - .azure-pipelines/noop-pipeline.yml
      - .azure-pipelines/monitoring.yml
      - .github/
      - .gitlab-ci.yml
      - blog/
      - docs/
      - tracer/dependabot/
      - tracer/README.MD
      - tracer/src/Datadog.Trace/DuckTyping/README.md
      - tracer/samples
      - tracer/build/_build/Build.GitHub.cs
      - tracer/build/_build/Build.Gitlab.cs
      - tracer/tools/PipelineMonitor
      - LICENSE
      - LICENSE-3rdparty.csv
      - NOTICE

schedules:
  - cron: "0 3 * * *"
    displayName: Daily 3am (UTC) build
    branches:
      include:
        - master
        - release/*
        - hotfix/*
        - /benchmarks/*
      exclude:
        - release/1.x
    always: true

  - cron: "*/6 1 * * Sat"
    displayName: Saturday CI, every 6 minutes from 1am
    branches:
      include:
        - master
    always: true

# Global variables
variables:
  buildConfiguration: Release
  dotnetCoreSdkLatestVersion: 7.0.101
  relativeArtifacts: /tracer/src/bin/artifacts
  monitoringHome: $(System.DefaultWorkingDirectory)/shared/bin/monitoring-home
  artifacts: $(System.DefaultWorkingDirectory)/tracer/src/bin/artifacts
  symbols: $(System.DefaultWorkingDirectory)/tracer/bin/symbols
  relativeRunnerTool: tracer/src/bin/runnerTool
  relativeRunnerStandalone: tracer/src/bin/runnerStandalone
  ddApiKey: $(DD_API_KEY)
  slackWebhookUrl: $(SLACK_WEBHOOK_URL)
  isMainRepository: $[eq(variables['GITHUB_REPOSITORY_NAME'], 'dd-trace-dotnet')]
  isMainBranch: $[in(variables['Build.SourceBranch'], 'refs/heads/master', 'refs/heads/main')]
  isMainOrReleaseBranch: $[or(in(variables['Build.SourceBranch'], 'refs/heads/master', 'refs/heads/main'), startsWith(variables['Build.SourceBranch'], 'refs/heads/release/'), startsWith(variables['Build.SourceBranch'], 'refs/heads/hotfix/'))]
  isPullRequest: $[eq(variables['Build.Reason'], 'PullRequest')]
  DD_DOTNET_TRACER_MSBUILD:
  NugetPackageDirectory: $(System.DefaultWorkingDirectory)/packages
  relativeNugetPackageDirectory: packages
  # For scheduled builds, only run benchmarks and throughput (and deps). Always do a full build on master.
  isBenchmarksOnlyBuild: ${{ and(eq(variables['Build.Reason'], 'Schedule'), not(in(variables['Build.SourceBranch'], 'refs/heads/master', 'refs/heads/main'))) }} # only works if you have a main branch
  dotnetToolTag: build-dotnet-tool
  Verify_DisableClipboard: true
  DiffEngine_Disabled: true
  OriginalCommitId: $[coalesce(variables['System.PullRequest.SourceCommitId'], variables['Build.SourceVersion'])]
  NUGET_ENABLE_EXPERIMENTAL_HTTP_RETRY: true
  DefaultTimeout: 60
  DD_INSTRUMENTATION_TELEMETRY_ENABLED: 0
  # Include all test frameworks when (variable is set) OR ((running on master/release/hotfix) and (NOT scheduled build)),
  IncludeAllTestFrameworks: $[or(eq(variables['run_all_test_frameworks'], 'true'), and(or(in(variables['Build.SourceBranch'], 'refs/heads/master', 'refs/heads/main'), startsWith(variables['Build.SourceBranch'], 'refs/heads/release/'), startsWith(variables['Build.SourceBranch'], 'refs/heads/hostfix/')), not(eq(variables['Build.Reason'], 'Schedule'))))]
  # Logger variables
  DD_LOGGER_DD_API_KEY: $(DD_API_KEY)
  DD_LOGGER_DD_SERVICE: dd-trace-dotnet
  DD_LOGGER_DD_ENV: CI
  DD_LOGGER_TF_BUILD: True
  DD_LOGGER_BUILD_BUILDID: $(Build.BuildId)
  DD_LOGGER_BUILD_DEFINITIONNAME: $(Build.DefinitionName)
  DD_LOGGER_BUILD_SOURCESDIRECTORY: $(Build.SourcesDirectory)
  DD_LOGGER_BUILD_REPOSITORY_URI: $(Build.Repository.Uri)
  DD_LOGGER_BUILD_SOURCEVERSION: $(Build.SourceVersion)
  DD_LOGGER_BUILD_SOURCEBRANCH: $(Build.SourceBranch)
  DD_LOGGER_BUILD_SOURCEBRANCHNAME: $(Build.SourceBranchName)
  DD_LOGGER_BUILD_SOURCEVERSIONMESSAGE: $(Build.SourceVersionMessage)
  DD_LOGGER_BUILD_REQUESTEDFORID: $(Build.RequestedForId)
  DD_LOGGER_BUILD_REQUESTEDFOREMAIL: $(Build.RequestedForEmail)
  DD_LOGGER_SYSTEM_TEAMFOUNDATIONSERVERURI: $(System.TeamFoundationServerUri)
  DD_LOGGER_SYSTEM_TEAMPROJECTID: $(System.TeamProjectId)
  DD_LOGGER_SYSTEM_STAGEDISPLAYNAME: $(System.StageDisplayName)
  DD_LOGGER_SYSTEM_JOBDISPLAYNAME: $(System.JobDisplayName)
  DD_LOGGER_SYSTEM_JOBID: $(System.JobId)
  DD_LOGGER_SYSTEM_PULLREQUEST_SOURCEREPOSITORYURI: $[variables['System.PullRequest.SourceRepositoryURI']]
  DD_LOGGER_SYSTEM_PULLREQUEST_SOURCECOMMITID: $[variables['System.PullRequest.SourceCommitId']]
  DD_LOGGER_SYSTEM_PULLREQUEST_SOURCEBRANCH: $[variables['System.PullRequest.SourceBranch']]
  DD_LOGGER_API_KEY_CHECKER_ENABLED: false
  DD_LOGGER_DD_TAGS: test.configuration.job:$(System.JobDisplayName)
  DD_LOGGER_ENABLED: true

# Declare the datadog agent as a resource to be used as a pipeline service
resources:
  containers:
  - container: dd_agent
    image: datadog/agent
    ports:
    - 8126:8126
    env:
      DD_API_KEY: $(ddApiKey)
      DD_INSIDE_CI: true

# Stages
stages:
# This step grabs the current commit of master, and records it for subsequent stages
# We use it to ensure that we are always running PRs against the same commit, even
# if master is updated while the build is in progress. This guards against CI flakiness
# where the first stages of the build execute against one merge commit, and later stages
# run against another

- stage: master_commit_id
  dependsOn: []
  jobs:
  - job: fetch
    timeoutInMinutes: 60 #default value
    pool:
      name: azure-linux-task-scale-set

    steps:
    - checkout: none
    - bash: |
        rm -rf ./s
        git clone --quiet --no-checkout --depth 1 --branch master $BUILD_REPOSITORY_URI ./s
        cd s
        MASTER_SHA=$(git rev-parse origin/master)
        rm -rf ./s
        echo "Using master commit ID $MASTER_SHA"
        echo "##vso[task.setvariable variable=master;isOutput=true]$MASTER_SHA"
      failOnStderr: true
      displayName: Fetch master id
      name: set_sha

- stage: generate_variables
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [generate_variables_job]

  - job: generate_variables_job
    timeoutInMinutes: 60 #default value
    dependsOn: []
    pool:
      name: azure-windows-scale-set-3

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml

    - powershell: |
        tracer/build.ps1 GenerateVariables
      displayName: Generate Matrices
      name: generate_variables_step

- stage: build_windows_tracer
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build]

  - job: build
    timeoutInMinutes: 60 #default value
    pool:
      name: azure-windows-scale-set-3
    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml

    - script: tracer\build.cmd BuildTracerHome BuildNativeLoader
      displayName: Build tracer home
      retryCountOnTaskFailure: 1

    - publish: $(monitoringHome)
      displayName: Upload Windows tracer home directory
      artifact: windows-tracer-home

    - publish: $(System.DefaultWorkingDirectory)
      displayName: Upload working directory after the managed build
      artifact: build-windows-working-directory

- stage: build_windows_profiler
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build]

  - job: build
    pool:
      name: azure-windows-scale-set-3
    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml

    - script: tracer\build.cmd BuildProfilerHome
      displayName: Build profiler home
      retryCountOnTaskFailure: 1

    - publish: $(monitoringHome)
      displayName: Upload Windows profiler home directory
      artifact: windows-profiler-home

    - publish: $(symbols)
      displayName: Upload Windows profiler symbols
      artifact: windows-profiler-symbols

    - publish: $(System.DefaultWorkingDirectory)/profiler/_build
      displayName: Upload Windows profiler directory
      artifact: windows-profiler-binaries

- stage: build_linux_tracer
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build]

  - job: build
    timeoutInMinutes: 60 #default value
    dependsOn: []
    strategy:
      matrix:
        centos7:
          baseImage: centos7
        alpine:
          baseImage: alpine
    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        baseImage: $(baseImage)
        command: "Clean CppCheckNativeSrc BuildTracerHome CppCheckNativeLoader BuildNativeLoader ExtractDebugInfoLinux"
        retryCountForRunCommand: 1

    - publish: $(monitoringHome)
      displayName: Uploading linux tracer home artifact
      artifact: linux-tracer-home-$(baseImage)

    - publish: $(System.DefaultWorkingDirectory)
      displayName: Upload working directory after the build
      artifact: build-linux-$(baseImage)-working-directory

    - publish: $(symbols)
      displayName: Upload linux tracer symbols
      artifact: linux-tracer-symbols-$(baseImage)

- stage: build_linux_profiler
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build]

  - job: build
    timeoutInMinutes: 60 #default value
    dependsOn: []
    strategy:
      matrix:
        centos7:
          baseImage: centos7
        alpine:
          baseImage: alpine
    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        baseImage: $(baseImage)
        command: "Clean BuildProfilerHome ExtractDebugInfoLinux"
        retryCountForRunCommand: 1

    - publish: $(System.DefaultWorkingDirectory)/profiler/_build
      displayName: Uploading linux profiler output build folder
      artifact: linux-profiler-binaries-$(baseImage)

    - publish: $(monitoringHome)
      displayName: Uploading linux profiler home artifact
      artifact: linux-profiler-home-$(baseImage)

    - publish: $(symbols)
      displayName: Upload linux profiler symbols
      artifact: linux-profiler-symbols-$(baseImage)

- stage: package_linux
  dependsOn: [master_commit_id, build_linux_tracer, build_linux_profiler]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [package]

  - job: package
    dependsOn: []
    timeoutInMinutes: 60 #default value
    strategy:
      matrix:
        centos7:
          baseImage: centos7
        alpine:
          baseImage: alpine
    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download tracer linux native binary
      inputs:
        artifact: linux-tracer-home-$(baseImage)
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download profiler linux native binary
      inputs:
        artifact: linux-profiler-home-$(baseImage)
        path: $(monitoringHome)

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        baseImage: $(baseImage)
        command: "ZipMonitoringHome"
        retryCountForRunCommand: 1

    - publish: $(artifacts)/linux-x64
      displayName: Upload linux-x64 packages
      artifact: linux-packages-$(baseImage)

    - publish: $(monitoringHome)
      displayName: Upload linux-x64 monitoring home
      artifact: linux-monitoring-home-$(baseImage)

- stage: build_arm64_tracer
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build]

  - job: build
    timeoutInMinutes: 60 #default value
    dependsOn: []
    pool:
      name: aws-arm64-auto-scaling
    workspace:
      clean: all
    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        baseImage: debian
        command: "Clean CppCheckNativeSrc BuildTracerHome CppCheckNativeLoader BuildNativeLoader ExtractDebugInfoLinux"
        retryCountForRunCommand: 1

    - publish: $(monitoringHome)
      displayName: Uploading linux tracer home artifact
      artifact: linux-tracer-home-arm64

    - publish: $(System.DefaultWorkingDirectory)
      displayName: Upload working directory after the build
      artifact: build-linux-arm64-working-directory

    - publish: $(symbols)
      displayName: Upload linux tracer symbols
      artifact: linux-tracer-symbols-arm64

- stage: build_arm64_profiler
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build]

  - job: build
    timeoutInMinutes: 60 #default value
    dependsOn: []
    pool:
      name: aws-arm64-auto-scaling
    workspace:
      clean: all
    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        baseImage: debian
        command: "Clean BuildProfilerHome ExtractDebugInfoLinux"
        retryCountForRunCommand: 1

    - publish: $(System.DefaultWorkingDirectory)/profiler/_build
      displayName: Uploading linux profiler output build folder
      artifact: linux-profiler-binaries-arm64

    - publish: $(monitoringHome)
      displayName: Uploading linux profiler home artifact
      artifact: linux-profiler-home-arm64

    - publish: $(symbols)
      displayName: Upload linux profiler symbols
      artifact: linux-profiler-symbols-arm64

- stage: package_arm64
  dependsOn: [master_commit_id, build_arm64_tracer, build_arm64_profiler]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [package]

  - job: package
    dependsOn: []
    timeoutInMinutes: 60 #default value
    pool:
      name: aws-arm64-auto-scaling

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download tracer arm64 native binary
      inputs:
        artifact: linux-tracer-home-arm64
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download profiler arm64 native binary
      inputs:
        artifact: linux-profiler-home-arm64
        path: $(monitoringHome)

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        baseImage: debian
        command: "ZipMonitoringHome"
        retryCountForRunCommand: 1

    - publish: $(artifacts)/linux-arm64
      displayName: Upload arm64 packages
      artifact: linux-packages-arm64

    - publish: $(monitoringHome)
      displayName: Upload arm64 monitoring home
      artifact: linux-monitoring-home-arm64

- stage: build_macos
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build]

  - job: build
    timeoutInMinutes: 60 #default value
    dependsOn: [ ]
    pool:
      vmImage: macos-11
    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml

    - script: brew install cppcheck
      displayName: Installing CppCheck

    - script: ./tracer/build.sh CppCheckNativeSrc BuildTracerHome CppCheckNativeLoader BuildNativeLoader
      displayName: Build tracer home
      retryCountOnTaskFailure: 1

    - publish: $(monitoringHome)
      displayName: Uploading macos profiler artifact
      artifact: macos-tracer-home

    - publish: $(System.DefaultWorkingDirectory)
      displayName: Upload working directory after the build
      artifact: build-macos-working-directory

- stage: package_windows
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [ build_windows_tracer, build_windows_profiler, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  pool:
    name: azure-windows-scale-set-3
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [msi_and_pack]

  - job: msi_and_pack
    steps:
      - template: steps/clone-repo.yml
        parameters:
          masterCommitId: $(masterCommitId)
      - template: steps/install-latest-dotnet-sdk.yml
      - template: steps/restore-working-directory.yml

      - task: DownloadPipelineArtifact@2
        displayName: Download windows profiler home
        inputs:
          artifact: windows-profiler-home
          path: $(monitoringHome)

      - script: tracer\build.cmd PackageTracerHome
        displayName: Build MSI and Tracer home
        retryCountOnTaskFailure: 1

      - publish: $(artifacts)/windows-tracer-home.zip
        displayName: Publish tracer-home.zip
        artifact: windows-tracer-home.zip

      - publish: $(artifacts)/x86/en-us
        displayName: Publish Windows x86 MSI
        artifact: windows-msi-x86

      - publish: $(artifacts)/x64/en-us
        displayName: Publish Windows x64 MSI
        artifact: windows-msi-x64

      - publish: $(artifacts)/nuget
        displayName: Publish NuGet packages
        artifact: nuget-packages

- stage: unit_tests_windows
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_windows_tracer, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  pool:
    name: azure-windows-scale-set-3

  jobs:
    - template: steps/update-github-status-jobs.yml
      parameters:
        jobs: [managed, native]

    - job: managed
      timeoutInMinutes: 60 #default value
      steps:
      - template: steps/clone-repo.yml
        parameters:
          masterCommitId: $(masterCommitId)
      - template: steps/install-dotnet.yml
      - template: steps/restore-working-directory.yml

      - script: tracer\build.cmd BuildAndRunManagedUnitTests --code-coverage
        displayName: Build and Test
        env:
          DD_LOGGER_DD_API_KEY: $(ddApiKey)

      - publish: tracer/build_data
        artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
        condition: succeededOrFailed()
        continueOnError: true

      - task: PublishTestResults@2
        displayName: publish test results
        inputs:
          testResultsFormat: VSTest
          testResultsFiles: tracer/build_data/results/**/*.trx
        condition: succeededOrFailed()

    - job: native
      timeoutInMinutes: 60 #default value
      steps:
      - template: steps/clone-repo.yml
        parameters:
          masterCommitId: $(masterCommitId)
      - template: steps/install-dotnet.yml
      - template: steps/restore-working-directory.yml

      - script: tracer\build.cmd BuildAndRunNativeUnitTests
        displayName: Build and Test
        env:
          DD_LOGGER_DD_API_KEY: $(ddApiKey)

      - task: PublishTestResults@2
        displayName: publish test results
        inputs:
          testResultsFiles: |
            tracer/test/**/test*.xml
            profiler/build_data/*.xml
        condition: succeededOrFailed()

- stage: unit_tests_macos
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_macos, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [managed]

  - job: managed
    timeoutInMinutes: 60 #default value
    pool:
      vmImage: macos-11
    steps:
      - template: steps/clone-repo.yml
        parameters:
          masterCommitId: $(masterCommitId)
      - template: steps/install-dotnet.yml
      - template: steps/restore-working-directory.yml
        parameters:
          artifact: build-macos-working-directory

      - script: ./tracer/build.sh BuildAndRunManagedUnitTests --code-coverage
        displayName: Build and Test
        env:
          DD_LOGGER_DD_API_KEY: $(ddApiKey)

      - publish: tracer/build_data
        artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
        condition: succeededOrFailed()
        continueOnError: true

      - task: PublishTestResults@2
        displayName: publish test results
        inputs:
          testResultsFormat: VSTest
          testResultsFiles: tracer/build_data/results/**/*.trx
        condition: succeededOrFailed()

- stage: unit_tests_linux
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_linux_tracer, build_linux_profiler, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [managed, native]

  - job: managed
    timeoutInMinutes: 60 #default value
    strategy:
      matrix:
        centos7:
          baseImage: centos7
        alpine:
          baseImage: alpine
    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildAndRunManagedUnitTests --code-coverage"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

  - job: native
    timeoutInMinutes: 60 #default value
    strategy:
      matrix:
        centos7:
          baseImage: centos7
        alpine:
          baseImage: alpine
    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    - task: DownloadPipelineArtifact@2
      displayName: Download linux profiler binaries
      inputs:
        artifact: linux-profiler-binaries-$(baseImage)
        path: $(System.DefaultWorkingDirectory)/profiler/_build

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildAndRunNativeUnitTests"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - task: PublishTestResults@2
      displayName: publish profiler test results
      inputs:
        testResultsFiles: profiler/build_data/*.xml
      condition: succeededOrFailed()

- stage: unit_tests_arm64
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_arm64_tracer, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
    - template: steps/update-github-status-jobs.yml
      parameters:
        jobs: [test]

    - job: test
      timeoutInMinutes: 60 #default value
      pool:
        name: aws-arm64-auto-scaling
      workspace:
        clean: all
      steps:
        - template: steps/clone-repo.yml
          parameters:
            masterCommitId: $(masterCommitId)
        - template: steps/restore-working-directory.yml
          parameters:
            artifact: build-linux-arm64-working-directory

        - template: steps/run-in-docker.yml
          parameters:
            build: true
            baseImage: debian
            command: "BuildAndRunManagedUnitTests"
            apiKey: $(DD_LOGGER_DD_API_KEY)

        - publish: tracer/build_data
          artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - task: PublishTestResults@2
          displayName: publish test results
          inputs:
            testResultsFormat: VSTest
            testResultsFiles: tracer/build_data/results/**/*.trx
          condition: succeededOrFailed()

- stage: integration_tests_windows
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_windows_tracer, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Win]

  - job: Win
    pool:
      name: azure-windows-scale-set-3
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_windows_matrix'] ]

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-dotnet-sdks.yml
      parameters:
        includeX86: true
    - template: steps/restore-working-directory.yml

# Cosmos is _way_ to flaky at the moment. Try enabling again at a later time
#    - powershell: |
#        Write-Host "Starting CosmosDB Emulator"
#        Import-Module "C:/Program Files/Azure Cosmos DB Emulator/PSModules/Microsoft.Azure.CosmosDB.Emulator"
#        Start-CosmosDbEmulator -Timeout 300
#      displayName: 'Start CosmosDB Emulator'
#      workingDirectory: $(Pipeline.Workspace)
#      retryCountOnTaskFailure: 5

    - powershell: |
        Write-Host "Initializing LocalDB"
        sqllocaldb.exe start
        sqlcmd.exe -S "(localdb)\MSSQLLocalDB" -i $(Build.Repository.LocalPath)\.azure-pipelines\prepare_localdb.sql
      displayName: 'Initialize LocalDB'
      workingDirectory: $(Build.Repository.LocalPath)

    - script: tracer\build.cmd BuildAndRunWindowsIntegrationTests BuildAndRunWindowsRegressionTests -Framework $(framework) --code-coverage
      displayName: Run integration tests
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/build_data
      displayName: Uploading integration_tests_windows tracer logs
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - script: tracer\build.cmd CheckBuildLogsForErrors
      displayName: Check logs for errors

- stage: integration_tests_windows_debugger
  condition: >
    and(
      succeeded(),
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsDebuggerChanged'], 'True')
    )
  dependsOn: [build_windows_tracer, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Win]

  - job: Win
    pool:
      name: azure-windows-scale-set-3
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_windows_debugger_matrix'] ]

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-dotnet-sdks.yml
      parameters:
        includeX86: true

    - template: steps/restore-working-directory.yml

    - script: tracer\build.cmd BuildAndRunDebuggerIntegrationTests -Framework $(framework) --TargetPlatform $(targetPlatform) --DebugType $(debugType) --Optimize $(optimize) --code-coverage
      displayName: Run integration tests
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/build_data
      displayName: Uploading integration_tests_windows_debugger tracer logs
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - script: tracer\build.cmd CheckBuildLogsForErrors
      displayName: Check logs for errors

- stage: integration_tests_windows_iis
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_windows_tracer, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]

  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [tracer]

  - job: tracer
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_windows_iis_matrix'] ]
    pool:
      name: azure-windows-scale-set-3
    variables:
      relativeMsiOutputDirectory: $(relativeArtifacts)/$(targetPlatform)/en-us

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml
      parameters:
        includeX86: true
    - template: steps/restore-working-directory.yml

    - script: tracer\build.cmd BuildAspNetIntegrationTests RunWindowsTracerIisIntegrationTests -Framework $(framework) --code-coverage
      displayName: RunWindowsIisTracerIntegrationTests
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/build_data
      displayName: Uploading integration_tests_windows_iis tracer logs
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - script: tracer\build.cmd CheckBuildLogsForErrors
      displayName: Check logs for errors

- stage: integration_tests_windows_iis_security
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_windows_tracer, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]

  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [security]

  - job: security
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_windows_iis_matrix'] ]
    pool:
      name: azure-windows-scale-set-3
    variables:
      relativeMsiOutputDirectory: $(relativeArtifacts)/$(targetPlatform)/en-us

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml
      parameters:
        includeX86: true
    - template: steps/restore-working-directory.yml

    - script: tracer\build.cmd BuildAspNetIntegrationTests RunWindowsSecurityIisIntegrationTests -Framework $(framework) --code-coverage
      displayName: RunWindowsIisSecurityIntegrationTests
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/build_data
      displayName: Uploading integration_tests_windows_iis tracer logs
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - script: tracer\build.cmd CheckBuildLogsForErrors
      displayName: Check logs for errors

- stage: integration_tests_azure_functions
  dependsOn: [build_windows_tracer, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]

  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [windows]

  - job: windows
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_windows_azure_functions_matrix'] ]
    pool:
      name: azure-windows-scale-set-3

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-dotnet-sdks.yml
    - template: steps/restore-working-directory.yml

    - script: |
        $(runtimeInstall)
        func
      displayName: 'Install Azure Functions core tools'
      workingDirectory: $(Pipeline.Workspace)
      retryCountOnTaskFailure: 5

    - script: |
        "%ProgramFiles(x86)%\Microsoft SDKs\Azure\Storage Emulator\AzureStorageEmulator.exe" start
      displayName: 'Start Azure Storage Emulator'
      workingDirectory: $(Pipeline.Workspace)
      retryCountOnTaskFailure: 5

    - script: tracer\build.cmd BuildAndRunWindowsAzureFunctionsTests -Framework $(framework) --code-coverage
      displayName: Run Azure Functions tests
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/build_data
      displayName: Uploading tracer logs
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - script: tracer\build.cmd CheckBuildLogsForErrors
      displayName: Check logs for errors

    - script: |
        $(runtimeUninstall)
      displayName: 'Uninstall Azure Functions core tools'
      workingDirectory: $(Pipeline.Workspace)
      condition: succeededOrFailed()
      continueOnError: true

- stage: static_analysis_tests_profiler
  condition: >
    and(
      succeeded(), 
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsProfilerChanged'], 'True')
    )
  dependsOn: [master_commit_id, generate_variables]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Win, Linux]

  - job: Win
    pool:
      name: azure-windows-scale-set-3
    timeoutInMinutes: 60 #default value

    steps:
    - powershell: |
        choco install cppcheck -y --version 2.9
        Write-Host "##vso[task.setvariable variable=PATH;]${env:PATH};C:\Program Files\Cppcheck";
        refreshenv
      displayName: Install CppCheck

    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-latest-dotnet-sdk.yml

    - script: tracer\build.cmd RunCppCheckProfiler RunClangTidyProfiler
      displayName: Run CppCheck and Clang-Tidy on Profiler

    - script: tracer\build.cmd CheckProfilerStaticAnalysisResults
      displayName: Check static analyzers results for errors

    - publish: profiler/build_data
      displayName: Publish Static Analysis Results
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

  - job: Linux
    timeoutInMinutes: 60 #default value
    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        command: "RunCppCheckProfiler RunClangTidyProfiler"

    - template: steps/run-in-docker.yml
      parameters:
        build: false
        target: builder
        command: "CheckProfilerStaticAnalysisResults"

    - publish: profiler/build_data
      displayName: Publish Static Analysis Results
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

- stage: msi_integration_tests_windows
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_windows_tracer, package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]

  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [msi_tests]

  - job: msi_tests
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_windows_msi_matrix'] ]
    pool:
      name: azure-windows-scale-set-3
    variables:
      relativeMsiOutputDirectory: $(relativeArtifacts)/$(targetPlatform)/en-us

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml
      parameters:
        includeX86: true
    - template: steps/restore-working-directory.yml

    - task: DownloadPipelineArtifact@2
      displayName: Download MSI
      inputs:
        artifact: windows-msi-$(targetPlatform)
        patterns: '**/*-$(targetPlatform).msi'
        path: $(System.DefaultWorkingDirectory)/$(relativeMsiOutputDirectory)

    - script: tracer\build.cmd BuildAspNetIntegrationTests -Framework $(framework)
      displayName: BuildWindowsIntegrationTests

    - script: |
        docker-compose build --build-arg dotnet_tracer_msi=.$(relativeMsiOutputDirectory)/*.msi --build-arg ENABLE_32_BIT=$(enable32bit) IntegrationTests.IIS
        docker-compose up -d IntegrationTests.IIS
      displayName: docker-compose start IntegrationTests.IIS
      retryCountOnTaskFailure: 5
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - script: tracer\build.cmd RunWindowsMsiIntegrationTests -Framework $(framework) --code-coverage
      displayName: RunWindowsIisIntegrationTests
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - task: DockerCompose@0
      displayName: docker-compose stop services
      inputs:
        containerregistrytype: Container Registry
        dockerComposeCommand: down
        projectName: ddtrace_$(Build.BuildNumber)
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      condition: succeededOrFailed()

    - publish: tracer/build_data
      displayName: Uploading integration_tests_windows_msi tracer logs
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - script: tracer\build.cmd CheckBuildLogsForErrors
      displayName: Check logs for errors

- stage: integration_tests_linux
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_linux, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Test, DockerTest]

  - job: Test
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_linux_matrix']]

    variables:
      TestAllPackageVersions: true
      IncludeMinorPackageVersions:  $[eq(variables.perform_comprehensive_testing, 'true')]

    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    # when we build samples separately, we could run this step and the docker-compose one below in //
    # (currently the docker-compose step relies on serverless samples)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildLinuxIntegrationTests --framework $(publishTargetFramework) --IncludeTestsRequiringDocker false"
        apikey: $(DD_LOGGER_DD_API_KEY)

    - task: DownloadPipelineArtifact@2
      displayName: Download linux monitoring home
      inputs:
        artifact: linux-monitoring-home-$(baseImage)
        path: $(monitoringHome)

    - task: DockerCompose@0
      displayName: docker-compose run --no-deps IntegrationTests
      inputs:
        containerregistrytype: Container Registry
        dockerComposeFileArgs: |
          baseImage=$(baseImage)
          framework=$(publishTargetFramework)
          DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
        dockerComposeCommand: run --no-deps --rm -e baseImage=$(baseImage) -e framework=$(publishTargetFramework) -e IncludeTestsRequiringDocker=false IntegrationTests
        projectName: ddtrace_$(Build.BuildNumber)
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - script: |
        sudo chmod -R 644 tracer/build_data/dumps/* || true
      displayName: Make dumps uploadable to AzDo
      condition: succeededOrFailed()

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "CheckBuildLogsForErrors"
        apiKey: $(DD_LOGGER_DD_API_KEY)

  - job: DockerTest
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_linux_matrix']]

    variables:
      TestAllPackageVersions: true
      IncludeMinorPackageVersions:  $[eq(variables.perform_comprehensive_testing, 'true')]

    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    # when we build samples separately, we could run this step and the docker-compose one below in //
    # (currently the docker-compose step relies on serverless samples)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildLinuxIntegrationTests --framework $(publishTargetFramework) --IncludeTestsRequiringDocker true"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - task: DownloadPipelineArtifact@2
      displayName: Download linux monitoring home
      inputs:
        artifact: linux-monitoring-home-$(baseImage)
        path: $(monitoringHome)

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build --build-arg baseImage=$(baseImage) --build-arg framework=$(publishTargetFramework) IntegrationTests
        docker-compose -p ddtrace_$(Build.BuildNumber) run --rm StartDependencies
      env:
        baseImage: $(baseImage)
        framework: $(publishTargetFramework)
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      displayName: docker-compose build IntegrationTests and run StartDependencies
      retryCountOnTaskFailure: 5

    - task: DockerCompose@0
      displayName: docker-compose run IntegrationTests
      inputs:
        containerregistrytype: Container Registry
        dockerComposeFileArgs: |
          baseImage=$(baseImage)
          framework=$(publishTargetFramework)
          DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
        dockerComposeCommand: run --rm -e baseImage=$(baseImage) -e framework=$(publishTargetFramework) -e IncludeTestsRequiringDocker=true IntegrationTests
        projectName: ddtrace_$(Build.BuildNumber)
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: DockerCompose@0
      displayName: docker-compose stop services
      inputs:
        containerregistrytype: Container Registry
        dockerComposeCommand: down
        projectName: ddtrace_$(Build.BuildNumber)
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      condition: succeededOrFailed()

    - script: |
        sudo chmod -R 644 tracer/build_data/dumps/* || true
      displayName: Make dumps uploadable to AzDo
      condition: succeededOrFailed()

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "CheckBuildLogsForErrors"
        apiKey: $(DD_LOGGER_DD_API_KEY)

  - job: Serverless
    timeoutInMinutes: 60

    variables:
      TestAllPackageVersions: false
      IncludeMinorPackageVersions:  false
      baseImage: "centos7"

    strategy:
      matrix:
        netcoreapp3_1:
          publishTargetFramework: "netcoreapp3.1"
          lambdaBaseImage: "public.ecr.aws/lambda/dotnet:core3.1"
        net5:
          publishTargetFramework: "net5.0"
          lambdaBaseImage: "public.ecr.aws/lambda/dotnet:5.0"
        net6:
          publishTargetFramework: "net6.0"
          lambdaBaseImage: "public.ecr.aws/lambda/dotnet:6"
        net7:
          publishTargetFramework: "net7.0"
          lambdaBaseImage: "public.ecr.aws/lambda/dotnet:7"
    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    - task: DownloadPipelineArtifact@2
      displayName: Download linux monitoring home
      inputs:
        artifact: linux-monitoring-home-$(baseImage)
        path: $(monitoringHome)

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildLinuxIntegrationTests --framework $(publishTargetFramework) --SampleName Samples.Aws.Lambda"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - script: |
        # Include the serverless dockerfile
        docker-compose -p ddtrace_$(Build.BuildNumber) \
          -f $(System.DefaultWorkingDirectory)/docker-compose.yml \
          -f docker-compose.serverless.yml \
          build \
          --build-arg baseImage=$(baseImage) \
          --build-arg framework=$(publishTargetFramework) \
          IntegrationTests.Serverless

        docker-compose -p ddtrace_$(Build.BuildNumber) \
          -f $(System.DefaultWorkingDirectory)/docker-compose.yml \
          -f docker-compose.serverless.yml \
          --build-arg framework=$(publishTargetFramework) \
          pull --include-deps StartDependencies.Serverless

        docker-compose -p ddtrace_$(Build.BuildNumber) \
          -f $(System.DefaultWorkingDirectory)/docker-compose.yml \
          -f docker-compose.serverless.yml \
          run --rm StartDependencies.Serverless
      env:
        baseImage: $(baseImage)
        framework: $(publishTargetFramework)
        lambdaBaseImage: $(lambdaBaseImage)
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      displayName: docker-compose build IntegrationTests.Serverless and run StartDependencies.Serverless
      retryCountOnTaskFailure: 5

    - task: DockerCompose@0
      displayName: docker-compose run IntegrationTests.Serverless
      inputs:
        containerregistrytype: Container Registry
        dockerComposeFileArgs: |
          baseImage=$(baseImage)
          framework=$(publishTargetFramework)
          lambdaBaseImage=$(lambdaBaseImage)
          DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
        dockerComposeCommand: run --rm -e baseImage=$(baseImage) -e framework=$(publishTargetFramework) IntegrationTests.Serverless
        additionalDockerComposeFiles: |
          docker-compose.serverless.yml
        projectName: ddtrace_$(Build.BuildNumber)
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - script: |
        mkdir -p tracer/build_data/docker

        docker-compose -p ddtrace_$(Build.BuildNumber) \
          -f $(System.DefaultWorkingDirectory)/docker-compose.yml \
          -f docker-compose.serverless.yml \
          logs \
          serverless-lambda-no-param-sync \
          serverless-lambda-one-param-sync \
          serverless-lambda-two-params-sync \
          serverless-lambda-no-param-sync-with-context \
          serverless-lambda-one-param-sync-with-context \
          serverless-lambda-two-params-sync-with-context \
          serverless-lambda-no-param-async \
          serverless-lambda-one-param-async \
          serverless-lambda-two-params-async \
          serverless-lambda-no-param-void \
          serverless-lambda-one-param-void \
          serverless-lambda-two-params-void \
          serverless-lambda-struct-param \
          serverless-lambda-nested-class-param \
          serverless-lambda-nested-struct-param \
          serverless-lambda-generic-dict-param \
          serverless-lambda-nested-generic-dict-param \
          serverless-lambda-doubly-nested-generic-dict-param \
          serverless-lambda-throwing \
          serverless-lambda-throwing-async \
          serverless-lambda-throwing-async-task \
          serverless-lambda-throwing-with-context \
          serverless-lambda-throwing-async-with-context \
          serverless-lambda-throwing-async-task-with-context

      env:
        baseImage: $(baseImage)
        framework: $(publishTargetFramework)
        DD_LOGGER_DD_API_KEY: $(DD_LOGGER_DD_API_KEY)
      displayName: docker-compose logs for serverless services
      condition: succeededOrFailed()
      retryCountOnTaskFailure: 5

    - task: DockerCompose@0
      displayName: docker-compose stop services
      inputs:
        containerregistrytype: Container Registry
        dockerComposeCommand: down
        projectName: ddtrace_$(Build.BuildNumber)
        additionalDockerComposeFiles: |
          docker-compose.serverless.yml
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      condition: succeededOrFailed()

    - script: |
        sudo chmod -R 644 tracer/build_data/dumps/* || true
      displayName: Make dumps uploadable to AzDo
      condition: succeededOrFailed()

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "CheckBuildLogsForErrors"
        apiKey: $(DD_LOGGER_DD_API_KEY)

- stage: integration_tests_linux_debugger
  condition: >
    and(
      succeeded(),
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsDebuggerChanged'], 'True')
    )
  dependsOn: [package_linux, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Test]

  - job: Test
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_linux_debugger_matrix']]

    variables:
      TestAllPackageVersions: true
      IncludeMinorPackageVersions:  $[eq(variables.perform_comprehensive_testing, 'true')]

    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    # when we build samples separately, we could run this step and the docker-compose one below in //
    # (currently the docker-compose step relies on serverless samples)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildDebuggerIntegrationTests --framework $(publishTargetFramework) --targetplatform x64 --debugtype portable --optimize $(optimize)"
        apikey: $(DD_LOGGER_DD_API_KEY)

    - task: DownloadPipelineArtifact@2
      displayName: Download linux monitoring home
      inputs:
        artifact: linux-monitoring-home-$(baseImage)
        path: $(monitoringHome)

    - task: DockerCompose@0
      displayName: docker-compose run --no-deps IntegrationTests.Debugger
      inputs:
        containerregistrytype: Container Registry
        dockerComposeFileArgs: |
          baseImage=$(baseImage)
          framework=$(publishTargetFramework)
          DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
        dockerComposeCommand: run --no-deps --rm -e baseImage=$(baseImage) -e framework=$(publishTargetFramework) IntegrationTests.Debugger
        projectName: ddtrace_$(Build.BuildNumber)
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - script: |
        sudo chmod -R 644 tracer/build_data/dumps/* || true
      displayName: Make dumps uploadable to AzDo
      condition: succeededOrFailed()

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

    - publish: tracer/test/snapshots
      displayName: Uploading snapshots
      artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "CheckBuildLogsForErrors"
        apiKey: $(DD_LOGGER_DD_API_KEY)

- stage: profiler_integration_tests_windows
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Win]

  - job: Win
    timeoutInMinutes: 60 #default value
    strategy:
      matrix:
        x86:
          targetPlatform: "x86"
        x64:
          targetPlatform: "x64"

    variables:
      IncludeMinorPackageVersions:  $[eq(variables.perform_comprehensive_testing, 'true')]

    pool:
      name: azure-windows-scale-set-3

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-dotnet-sdks.yml
      parameters:
        includeX86: true

    # windows-tracer-home.zip file contains profiler, tracer...
    - task: DownloadPipelineArtifact@2
      displayName: Download monitoring home zip
      inputs:
        artifact: windows-tracer-home.zip
        patterns: "windows-tracer-home.zip"
        path: $(Agent.TempDirectory)

    - task: ExtractFiles@1
      inputs:
        archiveFilePatterns: '$(Agent.TempDirectory)/windows-tracer-home.zip'
        destinationFolder: $(monitoringHome)

    - script: tracer\build.cmd BuildProfilerSamples BuildAndRunProfilerIntegrationTests --TargetPlatform $(targetPlatform)
      displayName: Run Profiler Integration tests
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - publish: profiler/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: profiler/build_data/results/**/*.trx
      condition: succeededOrFailed()

- stage: profiler_integration_tests_linux
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_linux, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Test]

  - job: Test
    timeoutInMinutes: 60 #default value
    strategy:
      matrix:
        centos7:
          baseImage: centos7
        alpine:
          baseImage: alpine

    variables:
      IncludeMinorPackageVersions:  $[eq(variables.perform_comprehensive_testing, 'true')]

    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    - task: DownloadPipelineArtifact@2
      displayName: Download linux monitoring home
      inputs:
        artifact: linux-monitoring-home-$(baseImage)
        path: $(monitoringHome)

    # when we build samples separately, we could run this step and the docker-compose one below in //
    # (currently the docker-compose step relies on serverless samples)
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildProfilerSamples"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "BuildAndRunProfilerCpuLimitTests"
        extraArgs: "--cpus 2 --env CONTAINER_CPUS=1"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "BuildAndRunProfilerCpuLimitTests"
        extraArgs: "--cpus 0.5 --env CONTAINER_CPUS=0.5"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - task: DockerCompose@0
      displayName: docker-compose run --no-deps ProfilerIntegrationTests
      inputs:
        containerregistrytype: Container Registry
        dockerComposeFileArgs: |
          baseImage=$(baseImage)
          DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
        dockerComposeCommand: run --no-deps --rm -e baseImage=$(baseImage) -e IncludeTestsRequiringDocker=false ProfilerIntegrationTests
        projectName: ddtrace_$(Build.BuildNumber)
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - publish: profiler/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: profiler/build_data/results/**/*.trx
      condition: succeededOrFailed()

- stage: asan_profiler_tests
  #address sanitizer tests
  condition: >
    and(
      succeeded(), 
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsProfilerChanged'], 'True')
    )
  dependsOn: [master_commit_id, generate_variables]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Linux,Windows]

  - job: Linux
    timeoutInMinutes: 60 #default value

    pool:
      name: azure-linux-scale-set

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-latest-dotnet-sdk.yml

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        command: "RunProfilerAsanTest -Framework net7.0"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - publish: profiler/build_data
      displayName: Uploading Address sanitizer test results
      artifact: _$(System.StageName)_$(Agent.JobName)_test_results_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: false

  - job: Windows
    timeoutInMinutes: 60 #default value
    pool:
      name: azure-windows-scale-set-3

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-latest-dotnet-sdk.yml
      parameters:
        includeX86: true

    - script: tracer\build.cmd RunProfilerAsanTest -Framework net7.0
      displayName: Run Profiler ASAN test

    - publish: profiler/build_data
      displayName: Uploading Address sanitizer test results
      artifact: _$(System.StageName)_$(Agent.JobName)_test_results_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: false

- stage: ubsan_profiler_tests
#undefined behavior sanitizer tests
  condition: > 
    and(
      succeeded(), 
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsProfilerChanged'], 'True')
    )
  dependsOn: [master_commit_id, generate_variables]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Linux]

  - job: Linux
    timeoutInMinutes: 60 #default value

    pool:
      name: azure-linux-scale-set

    steps:

    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-latest-dotnet-sdk.yml

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        target: builder
        command: "RunProfilerUbsanTest -Framework net7.0"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - publish: profiler/build_data
      displayName: Uploading test results
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: false

- stage: integration_tests_arm64
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_arm64, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
    TestAllPackageVersions: true
    IncludeMinorPackageVersions: $[eq(variables.perform_comprehensive_testing, 'true')]
    baseImage: debian

  jobs:
    - template: steps/update-github-status-jobs.yml
      parameters:
        jobs: [Test, DockerTest]

    - job: Test
      timeoutInMinutes: 60 #default value
      strategy:
        matrix:
          net5_0:
            publishTargetFramework: net5.0
          net6_0:
            publishTargetFramework: net6.0
          net7_0:
            publishTargetFramework: net7.0
      workspace:
        clean: all
      pool:
        name: aws-arm64-auto-scaling

      steps:
        - template: steps/clone-repo.yml
          parameters:
            masterCommitId: $(masterCommitId)

        - template: steps/restore-working-directory.yml
          parameters:
            artifact: build-linux-arm64-working-directory

        - template: steps/run-in-docker.yml
          parameters:
            build: true
            baseImage: $(baseImage)
            command: "BuildLinuxIntegrationTests --framework $(publishTargetFramework) --IncludeTestsRequiringDocker false"
            apiKey: $(DD_LOGGER_DD_API_KEY)

        - task: DownloadPipelineArtifact@2
          displayName: Download arm64 monitoring home
          inputs:
            artifact: linux-monitoring-home-arm64
            path: $(monitoringHome)

        - task: DockerCompose@0
          displayName: docker-compose run --no-deps IntegrationTests
          inputs:
            containerregistrytype: Container Registry
            dockerComposeFileArgs: |
              baseImage=$(baseImage)
              framework=$(publishTargetFramework)
              DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
            dockerComposeCommand: run --no-deps --rm -e baseImage=$(baseImage) -e framework=$(publishTargetFramework) -e IncludeTestsRequiringDocker=false IntegrationTests.ARM64
            projectName: ddtrace_$(Build.BuildNumber)
          env:
            DD_LOGGER_DD_API_KEY: $(ddApiKey)

        - publish: tracer/build_data
          artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - task: PublishTestResults@2
          displayName: publish test results
          inputs:
            testResultsFormat: VSTest
            testResultsFiles: tracer/build_data/results/**/*.trx
          condition: succeededOrFailed()

        - publish: tracer/test/snapshots
          displayName: Uploading snapshots
          artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - template: steps/run-in-docker.yml
          parameters:
            baseImage: $(baseImage)
            command: "CheckBuildLogsForErrors"
            apiKey: $(DD_LOGGER_DD_API_KEY)

    - job: DockerTest
      timeoutInMinutes: 60 #default value
      strategy:
        matrix:
          net5_0:
            publishTargetFramework: net5.0
          net6_0:
            publishTargetFramework: net6.0
          net7_0:
            publishTargetFramework: net7.0
      workspace:
        clean: all
      pool:
        name: aws-arm64-auto-scaling

      steps:
        - template: steps/clone-repo.yml
          parameters:
            masterCommitId: $(masterCommitId)

        - template: steps/restore-working-directory.yml
          parameters:
            artifact: build-linux-arm64-working-directory

        - template: steps/run-in-docker.yml
          parameters:
            build: true
            baseImage: $(baseImage)
            command: "BuildLinuxIntegrationTests --framework $(publishTargetFramework) --IncludeTestsRequiringDocker true"
            apiKey: $(DD_LOGGER_DD_API_KEY)

        - task: DownloadPipelineArtifact@2
          displayName: Download arm64 monitoring home
          inputs:
            artifact: linux-monitoring-home-arm64
            path: $(monitoringHome)

        - script: |
            docker-compose -p ddtrace_$(Build.BuildNumber) build --build-arg baseImage=$(baseImage) --build-arg framework=$(publishTargetFramework) IntegrationTests.ARM64
            docker-compose -p ddtrace_$(Build.BuildNumber) run --rm StartDependencies.ARM64
          env:
            baseImage: $(baseImage)
            framework: $(publishTargetFramework)
            DD_LOGGER_DD_API_KEY: $(ddApiKey)
          displayName: docker-compose build IntegrationTests and run StartDependencies
          retryCountOnTaskFailure: 5

        - task: DockerCompose@0
          displayName: docker-compose run IntegrationTests
          inputs:
            containerregistrytype: Container Registry
            dockerComposeFileArgs: |
              baseImage=$(baseImage)
              framework=$(publishTargetFramework)
              DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
            dockerComposeCommand: run --rm -e baseImage=$(baseImage) -e framework=$(publishTargetFramework) -e IncludeTestsRequiringDocker=true IntegrationTests.ARM64
            projectName: ddtrace_$(Build.BuildNumber)
          env:
            DD_LOGGER_DD_API_KEY: $(ddApiKey)

        - task: DockerCompose@0
          displayName: docker-compose stop services
          inputs:
            containerregistrytype: Container Registry
            dockerComposeCommand: down
            projectName: ddtrace_$(Build.BuildNumber)
          env:
            DD_LOGGER_DD_API_KEY: $(ddApiKey)
          condition: succeededOrFailed()

        - publish: tracer/build_data
          artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - task: PublishTestResults@2
          displayName: publish test results
          inputs:
            testResultsFormat: VSTest
            testResultsFiles: tracer/build_data/results/**/*.trx
          condition: succeededOrFailed()

        - publish: tracer/test/snapshots
          displayName: Uploading snapshots
          artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - template: steps/run-in-docker.yml
          parameters:
            baseImage: $(baseImage)
            command: "CheckBuildLogsForErrors"
            apiKey: $(DD_LOGGER_DD_API_KEY)

- stage: integration_tests_arm64_debugger
  condition: >
    and(
      succeeded(),
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsDebuggerChanged'], 'True')
    )
  dependsOn: [package_arm64, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]

  jobs:
    - template: steps/update-github-status-jobs.yml
      parameters:
        jobs: [Test]

    - job: Test
      timeoutInMinutes: 60 #default value
      strategy:
        matrix: $[stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.integration_tests_arm64_debugger_matrix']]

      workspace:
        clean: all
      pool:
        name: aws-arm64-auto-scaling

      steps:
        - template: steps/clone-repo.yml
          parameters:
            masterCommitId: $(masterCommitId)

        - template: steps/restore-working-directory.yml
          parameters:
            artifact: build-linux-arm64-working-directory

        - template: steps/run-in-docker.yml
          parameters:
            build: true
            baseImage: $(baseImage)
            command: "BuildDebuggerIntegrationTests --framework $(publishTargetFramework) --targetplatform x64 --debugtype portable --optimize $(optimize)"
            apiKey: $(DD_LOGGER_DD_API_KEY)

        - task: DownloadPipelineArtifact@2
          displayName: Download arm64 monitoring home
          inputs:
            artifact: linux-monitoring-home-arm64
            path: $(monitoringHome)

        - task: DockerCompose@0
          displayName: docker-compose run --no-deps IntegrationTests.ARM64.Debugger
          inputs:
            containerregistrytype: Container Registry
            dockerComposeFileArgs: |
              baseImage=$(baseImage)
              framework=$(publishTargetFramework)
              DD_LOGGER_DD_API_KEY=$(DD_LOGGER_DD_API_KEY)
            dockerComposeCommand: run --no-deps --rm -e baseImage=$(baseImage) -e framework=$(publishTargetFramework) IntegrationTests.ARM64.Debugger
            projectName: ddtrace_$(Build.BuildNumber)
          env:
            DD_LOGGER_DD_API_KEY: $(ddApiKey)

        - publish: tracer/build_data
          artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - task: PublishTestResults@2
          displayName: publish test results
          inputs:
            testResultsFormat: VSTest
            testResultsFiles: tracer/build_data/results/**/*.trx
          condition: succeededOrFailed()

        - publish: tracer/test/snapshots
          displayName: Uploading snapshots
          artifact: _$(System.StageName)_$(Agent.JobName)_snapshots_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - template: steps/run-in-docker.yml
          parameters:
            baseImage: $(baseImage)
            command: "CheckBuildLogsForErrors"
            apiKey: $(DD_LOGGER_DD_API_KEY)

- stage: exploration_tests_windows
  condition: >
    and(
      succeeded(),
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      or(
        eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsTracerChanged'],'True'),
        eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsProfilerChanged'], 'True'),
        eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsDebuggerChanged'], 'True')
      )
    )
  dependsOn: [build_windows_tracer, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]

  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [ExplorationTest]

  - job: ExplorationTest
    timeoutInMinutes: 100
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.exploration_tests_windows_matrix'] ]
    pool:
      name: azure-windows-scale-set-3

    # Enable the Datadog Agent service for this job
    services:
      dd_agent: dd_agent

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-dotnet-sdks.yml

    - template: steps/restore-working-directory.yml

    - script: tracer\build.cmd SetupExplorationTests -ExplorationTestUseCase $(explorationTestUseCase) -ExplorationTestName $(explorationTestName)
      displayName: SetupExplorationTest $(explorationTestUseCase) $(explorationTestName)

    - script: tracer\build.cmd RunExplorationTests -ExplorationTestUseCase $(explorationTestUseCase) -ExplorationTestName $(explorationTestName)
      displayName: RunExplorationTest
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - publish: tracer/build_data
      displayName: Uploading exploration_tests_windows tracer logs
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - script: tracer\build.cmd CheckBuildLogsForErrors
      displayName: Check logs for errors

- stage: exploration_tests_linux
  condition: >
    and(
      succeeded(),
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      or(
        eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsTracerChanged'],'True'),
        eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsProfilerChanged'], 'True'),
        eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsDebuggerChanged'], 'True')
      )
    )
  dependsOn: [package_linux, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Test]

  - job: Test
    timeoutInMinutes: 60 #default value
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.exploration_tests_linux_matrix'] ]

    pool:
      name: azure-linux-scale-set

    # Enable the Datadog Agent service for this job
    services:
      dd_agent: dd_agent

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    # Doing a clean of obj files _before_ restore to remove build output from previous runs
    # Can't do a full clean, as otherwise restore-working-directory fails
    # Only necessary for ARM64, but shouldn't cause any harm on others
    # Can't ifdef it as depends on a matrix variable
    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "CleanObjFiles"

    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(baseImage)-working-directory

    - template: steps/run-in-docker.yml
      parameters:
        build: false
        baseImage: $(baseImage)
        command: "SetupExplorationTests -ExplorationTestUseCase $(explorationTestUseCase) --explorationTestName $(explorationTestName) --framework $(publishTargetFramework)"
        apiKey: $(DD_LOGGER_DD_API_KEY)

    - task: DockerCompose@0
      displayName: docker-compose build ExplorationTests
      env:
        baseImage: $(baseImage)
        azdo_network: $(agent.containernetwork)
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      inputs:
        containerregistrytype: Container Registry
        additionalDockerComposeFiles: docker-compose.ci.azdo.yml
        dockerComposeCommand: build --build-arg baseImage=$(baseImage) --build-arg explorationTestUseCase=$(explorationTestUseCase) --build-arg explorationTestName=$(explorationTestName) --build-arg framework=$(publishTargetFramework) ExplorationTests

    - task: DockerCompose@0
      displayName: docker-compose run ExplorationTests
      env:
        azdo_network: $(agent.containernetwork)
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      inputs:
        containerregistrytype: Container Registry
        additionalDockerComposeFiles: docker-compose.ci.azdo.yml
        dockerComposeFileArgs: |
          baseImage=$(baseImage)
          framework=$(publishTargetFramework)
          explorationTestUseCase=$(explorationTestUseCase)
          explorationTestName=$(explorationTestName)
        dockerComposeCommand: run --rm -e DD_AGENT_HOST=dd_agent -e baseImage=$(baseImage) -e explorationTestUseCase=$(explorationTestUseCase) -e explorationTestName=$(explorationTestName) -e framework=$(publishTargetFramework) ExplorationTests

    - task: DockerCompose@0
      displayName: docker-compose stop services
      inputs:
        containerregistrytype: Container Registry
        dockerComposeCommand: down
        projectName: ddtrace_$(Build.BuildNumber)
      condition: succeededOrFailed()

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "CheckBuildLogsForErrors"

- stage: benchmarks
  condition: and(succeeded(), eq(variables.isMainRepository, true))
  dependsOn: [build_windows_tracer, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Windows, compare_benchmarks]

  #### Windows

  - job: Windows
    strategy:
      matrix:
        BenchmarkAgent1:
          agent: "BenchmarkAgent1"
        BenchmarkAgent2:
          agent: "BenchmarkAgent2"
        BenchmarkAgent3:
          agent: "BenchmarkAgent3"
        BenchmarkAgent4:
          agent: "BenchmarkAgent4"
        BenchmarkAgent5:
          agent: "BenchmarkAgent5"
        BenchmarkAgent6:
          agent: "BenchmarkAgent6"

    timeoutInMinutes: 30
    pool:
      name: $(agent)

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-dotnet-sdks.yml
    - template: steps/restore-working-directory.yml

    - script: tracer\build.cmd RunBenchmarks
      displayName: RunBenchmarks
      env:
        DD_CIVISIBILITY_AGENTLESS_ENABLED: true
        DD_API_KEY: $(ddApiKey)

    - publish: tracer/build_data/benchmarks
      artifact: benchmarks_results_$(agent)

  - job: compare_benchmarks
    timeoutInMinutes: 60 #default value
    dependsOn: [ Windows ]
    pool:
      vmImage: windows-2022

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-latest-dotnet-sdk.yml

    - task: DownloadPipelineArtifact@2
      displayName: Download results BenchmarkAgent1
      inputs:
        artifact: benchmarks_results_BenchmarkAgent1
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks

    - task: DownloadPipelineArtifact@2
      displayName: Download results BenchmarkAgent2
      inputs:
        artifact: benchmarks_results_BenchmarkAgent2
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks

    - task: DownloadPipelineArtifact@2
      displayName: Download results BenchmarkAgent3
      inputs:
        artifact: benchmarks_results_BenchmarkAgent3
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks

    - task: DownloadPipelineArtifact@2
      displayName: Download results BenchmarkAgent4
      inputs:
        artifact: benchmarks_results_BenchmarkAgent4
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks

    - task: DownloadPipelineArtifact@2
      displayName: Download results BenchmarkAgent5
      inputs:
        artifact: benchmarks_results_BenchmarkAgent5
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks

    - task: DownloadPipelineArtifact@2
      displayName: Download results BenchmarkAgent6
      inputs:
        artifact: benchmarks_results_BenchmarkAgent6
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks

    # upload the combined results for simplicity in other pipelines
    - publish: tracer/build_data/benchmarks
      artifact: benchmarks_results

    - script: tracer\build.cmd CompareBenchmarksResults
      continueOnError: true
      displayName: Compare Benchmarks
      condition: and(succeeded(), eq(variables.isPullRequest, true))
      env:
        PR_NUMBER: $(System.PullRequest.PullRequestNumber)
        AZURE_DEVOPS_TOKEN: $(AZURE_DEVOPS_TOKEN)
        GITHUB_TOKEN: $(GITHUB_TOKEN)


- stage: dotnet_tool
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [build_windows_tracer, build_windows_profiler, build_linux_tracer, build_linux_profiler, build_arm64_tracer, build_arm64_profiler, build_macos, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [build_runner_tool_and_standalone]

  - job: build_runner_tool_and_standalone
    timeoutInMinutes: 60 #default value

    pool:
      name: azure-windows-scale-set-3

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml
    - template: steps/restore-working-directory.yml

    # Download everything to monitoring home
    # BuildBundleNuget moves everything to the required folders
    - task: DownloadPipelineArtifact@2
      displayName: Download linux tracer home
      inputs:
        artifact: linux-tracer-home-centos7
        patterns: |
          **/*.so
          **/loader.conf
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download alpine tracer home
      inputs:
        artifact: linux-tracer-home-alpine
        patterns:  |
          **/*.so
          **/loader.conf
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download arm64 tracer home
      inputs:
        artifact: linux-tracer-home-arm64
        patterns:  |
          **/*.so
          **/loader.conf
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download osx tracer home
      inputs:
        artifact: macos-tracer-home
        patterns:  |
          **/*.dylib
          **/loader.conf
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download windows profiler home
      inputs:
        artifact: windows-profiler-home
        patterns: "**/*.dll"
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download linux profiler home
      inputs:
        artifact: linux-profiler-home-centos7
        patterns:  |
          **/*.so
          **/loader.conf
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download alpine profiler home
      inputs:
        artifact: linux-profiler-home-alpine
        patterns:  |
          **/*.so
          **/loader.conf
        path: $(monitoringHome)

    - task: DownloadPipelineArtifact@2
      displayName: Download arm64 profiler home
      inputs:
        artifact: linux-profiler-home-arm64
        patterns:  |
          **/*.so
          **/loader.conf
        path: $(monitoringHome)

    - script: tracer\build.cmd CreateBundleHome BuildBundleNuget BuildRunnerTool PackRunnerToolNuget BuildStandaloneTool
      displayName: Build Bundle NuGet and runner tools

    - publish: $(artifacts)/nuget/bundle
      displayName: Uploading Bundle package
      artifact: bundle-nuget-package

    - publish: $(artifacts)/nuget/dd-trace
      displayName: Uploading runner dotnet tool artifact
      artifact: runner-dotnet-tool

    - publish: $(artifacts)/dd-trace-win-x64.zip
      displayName: Uploading runner standalone win-x64 artifact
      artifact: runner-standalone-win-x64

    - publish: $(artifacts)/dd-trace-win-x86.zip
      displayName: Uploading runner standalone win-x86 artifact
      artifact: runner-standalone-win-x86

    - publish: $(artifacts)/dd-trace-linux-x64.tar.gz
      displayName: Uploading runner standalone linux-x64 artifact
      artifact: runner-standalone-linux-x64

    - publish: $(artifacts)/dd-trace-linux-musl-x64.tar.gz
      displayName: Uploading runner standalone linux-musl-x64 artifact
      artifact: runner-standalone-linux-musl-x64

    - publish: $(artifacts)/dd-trace-linux-arm64.tar.gz
      displayName: Uploading runner standalone linux-arm64 artifact
      artifact: runner-standalone-linux-arm64

    - publish: $(artifacts)/dd-trace-osx-x64.tar.gz
      displayName: Uploading runner standalone osx-x64 artifact
      artifact: runner-standalone-osx-x64

    - powershell: |
        echo "##vso[build.addbuildtag]$(dotnetToolTag)"
      displayName: Add $(dotnetToolTag) build tag

- stage: tool_artifacts_tests_windows
  dependsOn: [dotnet_tool, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
    runnerTool: $(System.DefaultWorkingDirectory)/$(relativeRunnerTool)
    runnerStandalone: $(System.DefaultWorkingDirectory)/$(relativeRunnerStandalone)
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [test]

  - job: test
    timeoutInMinutes: 60 #default value
    strategy:
      matrix:
        windows-x86:
          targetPlatform: "x86"
        windows-x64:
          targetPlatform: "x64"

    pool:
      name: azure-windows-scale-set-3

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-latest-dotnet-sdk.yml
      parameters:
        includeX86: true
    - template: steps/restore-working-directory.yml

    - task: DownloadPipelineArtifact@2
      displayName: Download tool runner
      inputs:
        artifact: runner-dotnet-tool
        path: $(runnerTool)

    - task: DownloadPipelineArtifact@2
      displayName: Download standalone runner
      inputs:
        artifact: runner-standalone-win-$(targetPlatform)
        path: $(Agent.TempDirectory)/runner

    - task: ExtractFiles@1
      inputs:
        archiveFilePatterns: '$(Agent.TempDirectory)/runner/*.zip'
        destinationFolder: $(runnerStandalone)
        cleanDestinationFolder: false

    - script: tracer\build.cmd BuildAndRunToolArtifactTests --ToolSource $(runnerTool)
      displayName: Build and Test tool
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - script: tracer\build.cmd RunToolArtifactTests --ToolDestination $(runnerStandalone)
      displayName: Test standalone
      env:
        DD_LOGGER_DD_API_KEY: $(ddApiKey)

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

- stage: tool_artifacts_tests_linux
  dependsOn: [dotnet_tool, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
    runnerTool: $(System.DefaultWorkingDirectory)/$(relativeRunnerTool)
    runnerStandalone: $(System.DefaultWorkingDirectory)/$(relativeRunnerStandalone)
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [test]

  - job: test
    timeoutInMinutes: 60 #default value
    strategy:
      matrix:
        centos7:
          name: centos7
          baseImage: centos7
          artifactSuffix: linux-x64
          poolName: azure-linux-scale-set
        alpine:
          name: alpine
          baseImage: alpine
          artifactSuffix: linux-musl-x64
          poolName: azure-linux-scale-set
        arm64:
          name: arm64
          baseImage: debian
          artifactSuffix: linux-arm64
          poolname: aws-arm64-auto-scaling

    pool:
      name: $(poolName)

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/restore-working-directory.yml
      parameters:
        artifact: build-linux-$(name)-working-directory

    - task: DownloadPipelineArtifact@2
      displayName: Download tool runner
      inputs:
        artifact: runner-dotnet-tool
        path: $(runnerTool)

    - task: DownloadPipelineArtifact@2
      displayName: Download standalone runner
      inputs:
        artifact: runner-standalone-$(artifactSuffix)
        path: $(Agent.TempDirectory)/runner

    - task: ExtractFiles@1
      inputs:
        archiveFilePatterns: '$(Agent.TempDirectory)/runner/*.tar.gz'
        destinationFolder: $(runnerStandalone)
        cleanDestinationFolder: false

    - script: |
        ls $(runnerStandalone)
        chmod +x $(runnerStandalone)/dd-trace
      displayName: chmod

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: $(baseImage)
        command: "BuildAndRunToolArtifactTests --ToolSource /project/$(relativeRunnerTool)"

    - template: steps/run-in-docker.yml
      parameters:
        baseImage: $(baseImage)
        command: "RunToolArtifactTests --ToolDestination /project/$(relativeRunnerStandalone)"

    - task: PublishTestResults@2
      displayName: publish test results
      inputs:
        testResultsFormat: VSTest
        testResultsFiles: tracer/build_data/results/**/*.trx
      condition: succeededOrFailed()

- stage: upload_to_s3
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), eq(variables.isMainRepository, true))
  dependsOn: [package_windows, package_linux, package_arm64, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - job: s3_upload
    timeoutInMinutes: 60 #default value

    pool:
      vmImage: ubuntu-20.04

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - script: |
        mkdir s3_upload
      displayName: create s3_upload folder

    - task: DownloadPipelineArtifact@2
      displayName: Download x64 Windows MSI
      inputs:
        artifact: windows-msi-x64
        patterns: '**/*x64.msi'
        path: s3_upload

    - task: DownloadPipelineArtifact@2
      displayName: Download linux-packages
      inputs:
        artifact: linux-packages-centos7
        patterns: '**/*amd64.deb'
        path: s3_upload

    # for prerelease versions, rename datadog-dotnet-apm-{version}-amd64.deb
    # to datadog-dotnet-apm-{version}-{tag}-amd64.deb (i.e. add the prerelease tag)
    # by copying most of the filename from datadog-dotnet-apm-{version}-{tag}-x64.msi
    - script: |
        MSI_NAME=$(ls s3_upload/*.msi)
        PACKAGE_NAME=${MSI_NAME::-8}
        echo Renaming deb package to $PACKAGE_NAME-amd64.deb
        mv s3_upload/*.deb $PACKAGE_NAME-amd64.deb
      displayName: Rename deb package name to match MSI name

    # Create index.txt file with the following format:
    # BRANCH_NAME
    # SHA
    # ARTIFACT WILDCARD (datadog-dotnet-apm-vX.X.X-*)
    # COMMIT AUTHOR
    # Note: For the branch name, normalize 'refs/heads/<branch>' to '<branch>' and 'refs/tags/<tag_name>' to 'tags/<tag_name>'
    - script: |
        INDEX_FILE=$(pwd)/s3_upload/index.txt
        echo $(Build.SourceBranch) | sed 's/refs\/heads\///g' | sed 's/refs\/tags\//tags\//g' >> $INDEX_FILE
        git rev-parse HEAD >> $INDEX_FILE
        pushd s3_upload && name=$(ls *.deb) && echo "${name::-9}*" >> $INDEX_FILE && popd
        git show -s --format='%ae' HEAD >> $INDEX_FILE
        echo Generated index.txt file:
        cat $INDEX_FILE
      displayName: Write index.txt

    - script: tree s3_upload
      displayName: 'tree s3_upload'

    - script: |
        sudo apt-get install -y unzip python3-setuptools
        curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
        unzip awscli-bundle.zip
        sudo python3 ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
        aws --version
      displayName: Install AWS CLI

    - script: aws configure set aws_access_key_id $SECRET
      displayName: Authenticate aws_access_key_id
      env:
        SECRET: $(AWS_ACCESS_KEY_ID)

    - script: aws configure set aws_secret_access_key $SECRET
      displayName: Authenticate aws_secret_access_key
      env:
        SECRET: $(AWS_SECRET_ACCESS_KEY)

    # by default, run this step on master branch only.
    # use "push_artifacts_to_s3" to override:
    #   "true": run this step
    #   "false": do NOT run this step
    #   else: run this stage if branch is master

    - script: aws --region us-east-1 s3 cp s3_upload s3://datadog-reliability-env/dotnet/ --recursive --debug
      displayName: Upload deb, MSI, index.txt to s3
      condition: >
        and(
          succeeded(),
          ne(variables['push_artifacts_to_s3'], 'false'),
          or(
            eq(variables['push_artifacts_to_s3'], 'true'),
            eq(variables.isMainBranch, true)
          )
        )

- stage: upload_to_azure
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), eq(variables.isMainRepository, true))
  dependsOn: [package_windows, package_linux, package_arm64, dotnet_tool, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
    - job: upload
      timeoutInMinutes: 60 #default value
      pool:
        vmImage: ubuntu-20.04
      steps:
        - template: steps/clone-repo.yml
          parameters:
            masterCommitId: $(masterCommitId)

        - task: DownloadPipelineArtifact@2
          displayName: Download NuGet packages
          inputs:
            artifact: nuget-packages
            path: $(Build.ArtifactStagingDirectory)

        # set the version from the package name
        - bash: |
            NUGET_NAME=$(basename $(Build.ArtifactStagingDirectory)/Datadog.Trace.OpenTracing.*.nupkg)
            VERSION_NUMBER=${NUGET_NAME:26:-6}
            echo "detected version: $VERSION_NUMBER"
            echo "##vso[task.setvariable variable=tracer_version]$VERSION_NUMBER"
          displayName: Extract version number

        # Linux packages
        - task: DownloadPipelineArtifact@2
          displayName: Download linux Alpine packages
          inputs:
            artifact: linux-packages-alpine
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download linux CentOS7 packages
          inputs:
            artifact: linux-packages-centos7
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download linux Arm64 packages
          inputs:
            artifact: linux-packages-arm64
            path: $(Build.ArtifactStagingDirectory)

        # Linux symbols
        - task: DownloadPipelineArtifact@2
          displayName: Download linux profiler Alpine symbols
          inputs:
            artifact: linux-profiler-symbols-alpine
            path: $(Build.ArtifactStagingDirectory)/symbols/linux-musl-x64

        - task: DownloadPipelineArtifact@2
          displayName: Download linux profiler CentOS7 symbols
          inputs:
            artifact: linux-profiler-symbols-centos7
            path: $(Build.ArtifactStagingDirectory)/symbols/linux-x64

        - task: DownloadPipelineArtifact@2
          displayName: Download linux profiler Arm64 symbols
          inputs:
            artifact: linux-profiler-symbols-arm64
            path: $(Build.ArtifactStagingDirectory)/symbols/linux-arm64

        - task: DownloadPipelineArtifact@2
          displayName: Download linux tracer Alpine symbols
          inputs:
            artifact: linux-tracer-symbols-alpine
            path: $(Build.ArtifactStagingDirectory)/symbols/linux-musl-x64

        - task: DownloadPipelineArtifact@2
          displayName: Download linux tracer CentOS7 symbols
          inputs:
            artifact: linux-tracer-symbols-centos7
            path: $(Build.ArtifactStagingDirectory)/symbols/linux-x64

        - task: DownloadPipelineArtifact@2
          displayName: Download linux tracer Arm64 symbols
          inputs:
            artifact: linux-tracer-symbols-arm64
            path: $(Build.ArtifactStagingDirectory)/symbols/linux-arm64

        - bash: |
            tar -zcf  $(Build.ArtifactStagingDirectory)/linux-native-symbols.tar.gz ./symbols
            rm -rf $(Build.ArtifactStagingDirectory)/symbols
          displayName: Tar native linux symbols
          failOnStderr: true
          workingDirectory: $(Build.ArtifactStagingDirectory)


        # NuGet
        - task: DownloadPipelineArtifact@2
          displayName: Download bundle nuget package
          inputs:
            artifact: bundle-nuget-package
            path: $(Build.ArtifactStagingDirectory)

        # runner tool
        - task: DownloadPipelineArtifact@2
          displayName: Download runner dotnet tool
          inputs:
            artifact: runner-dotnet-tool
            patterns: "*.nupkg"
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download standalone dotnet tool win-x64
          inputs:
            artifact: runner-standalone-win-x64
            patterns: "*.zip"
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download standalone dotnet tool linux-x64
          inputs:
            artifact: runner-standalone-linux-x64
            patterns: "*.tar.gz"
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download standalone dotnet tool linux-musl-x64
          inputs:
            artifact: runner-standalone-linux-musl-x64
            patterns: "*.tar.gz"
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download standalone dotnet tool linux-arm64
          inputs:
            artifact: runner-standalone-linux-arm64
            patterns: "*.tar.gz"
            path: $(Build.ArtifactStagingDirectory)

        # release artifacts
        - publish: "$(Build.ArtifactStagingDirectory)"
          displayName: Publish release artifacts
          artifact: $(tracer_version)-release-artifacts

        # We don't include the MSIs in the artifact upload as they're
        # not signed, and we use the windows-tracer-home.zip file from
        # GitLab so that it matches the native symbols file,
        # but we include them all in the push to Azure
        - task: DownloadPipelineArtifact@2
          displayName: Download Windows tracer home
          inputs:
            artifact: windows-tracer-home.zip
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download x64 MSI
          inputs:
            artifact: windows-msi-x64
            path: $(Build.ArtifactStagingDirectory)

        - task: DownloadPipelineArtifact@2
          displayName: Download x86 MSI
          inputs:
            artifact: windows-msi-x86
            path: $(Build.ArtifactStagingDirectory)

        - bash: |
            az storage blob upload-batch \
              --destination "$(AZURE_STORAGE_CONTAINER_NAME)" \
              --destination-path "$(Build.SourceVersion)" \
              --source "$(Build.ArtifactStagingDirectory)"
          displayName: Upload blobs to Azure
          condition: >
            and(
              succeeded(),
              ne(variables['push_artifacts_to_azure_storage'], 'false'),
              or(
                eq(variables['push_artifacts_to_azure_storage'], 'true'),
                eq(variables.isMainBranch, true)
              )
            )
          env:
            AZURE_STORAGE_ACCOUNT: $(AZURE_STORAGE_ACCOUNT_NAME)
            AZURE_STORAGE_SAS_TOKEN: $(AZURE_STORAGE_SHARED_ACCESS_TOKEN)

        - bash: ls "$(Build.ArtifactStagingDirectory)" > index.txt
          displayName: Write file list to index.txt

        - bash: echo "$(Build.SourceVersion)" > sha.txt
          displayName: Write commit hash to sha.txt

        - bash: echo "$(tracer_version)" > version.txt
          displayName: Write tracer version number to version.txt

        - bash: |
            az storage blob upload --container-name "$(AZURE_STORAGE_CONTAINER_NAME)" --file "index.txt" --name "index.txt" --overwrite true
            az storage blob upload --container-name "$(AZURE_STORAGE_CONTAINER_NAME)" --file "sha.txt" --name "sha.txt" --overwrite true
            az storage blob upload --container-name "$(AZURE_STORAGE_CONTAINER_NAME)" --file "version.txt" --name "version.txt" --overwrite true
          displayName: Upload indexes to Azure
          condition: and(succeeded(), eq(variables.isMainBranch, true))
          env:
            AZURE_STORAGE_ACCOUNT: $(AZURE_STORAGE_ACCOUNT_NAME)
            AZURE_STORAGE_SAS_TOKEN: $(AZURE_STORAGE_SHARED_ACCESS_TOKEN)

- stage: upload_container_images
  condition: and(succeeded(), eq(variables['Build.Reason'], 'IndividualCI'), eq(variables.isMainRepository, true), eq(variables.isMainOrReleaseBranch, true))
  dependsOn: [upload_to_azure]
  jobs:
    - job: upload
      timeoutInMinutes: 60 #default value
      pool:
        vmImage: ubuntu-20.04
      steps:
      - checkout: none
      - bash: |
          echo "Creating dispatch event for https://github.com/DataDog/dd-trace-dotnet/actions/workflows/lib-injection.yml with ref=$(Build.SourceBranch) and azdo_build_id=$(Build.BuildId)"
          curl \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: token $GITHUB_TOKEN"\
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/DataDog/dd-trace-dotnet/actions/workflows/lib-injection.yml/dispatches \
            -d '{"ref":"$(Build.SourceBranch)","inputs":{"azdo_build_id":"$(Build.BuildId)"}}'
        displayName: Start lib-injection GitHub Actions worfklow
        env:
          GITHUB_TOKEN: $(GITHUB_TOKEN)

      - bash: |
          echo "Creating dispatch event for https://github.com/DataDog/dd-trace-dotnet/actions/workflows/docker-base-images.yml with ref=$(Build.SourceBranch) and azdo_build_id=$(Build.BuildId) and is_snapshot=$(isMainBranch)"
          curl \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: token $GITHUB_TOKEN"\
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/DataDog/dd-trace-dotnet/actions/workflows/docker-base-images.yml/dispatches \
            -d '{"ref":"$(Build.SourceBranch)","inputs":{"azdo_build_id":"$(Build.BuildId)","is_snapshot":"$(isMainBranch)"}}'
        displayName: Start the generation of docker base images on GitHub Actions worfklow
        env:
          GITHUB_TOKEN: $(GITHUB_TOKEN)

- stage: throughput
  condition: and(succeeded(), eq(variables.isMainRepository, true))
  dependsOn: [package_linux, package_arm64, build_windows_tracer, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
    # By default all throughput tests happen on release or master branches only, or when running a benchmarks only build. Overridable by setting 'run_extended_throughput_tests' to true
    runExtendedThroughputTests: $[or(eq(variables.isMainOrReleaseBranch, 'true'), not(eq(variables['isBenchmarksOnlyBuild'], 'False')), eq(variables.run_extended_throughput_tests, 'true'))]
    CrankDir: $(System.DefaultWorkingDirectory)/tracer/build/crank
  pool: Throughput
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Linux64, Windows64, LinuxArm64]
  #### Throughput Linux 64, windows 64, linux arm 64

  - job: Linux64
    timeoutInMinutes: 60

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download linux native binary
      inputs:
        artifact: linux-monitoring-home-centos7
        path: $(System.DefaultWorkingDirectory)/tracer/tracer-home-linux

    - script: |
        test ! -s "tracer/tracer-home-linux/linux-x64/Datadog.Trace.ClrProfiler.Native.so" && echo "tracer/tracer-home-linux/linux-x64/Datadog.Trace.ClrProfiler.Native.so (native loader) does not exist" && exit 1
        test ! -s "tracer/tracer-home-linux/linux-x64/Datadog.Tracer.Native.so" && echo "tracer/tracer-home-linux/linux-x64/Datadog.Tracer.Native.so does not exist" && exit 1
        test ! -s "tracer/tracer-home-linux/linux-x64/libddwaf.so" && echo "tracer/tracer-home-linux/linux-x64/libddwaf.so does not exist" && exit 1
        mkdir -p tracer/bin/netcoreapp3.1
        cp tracer/tracer-home-linux/netcoreapp3.1/Datadog.Trace.dll tracer/bin/netcoreapp3.1/Datadog.Trace.dll 
        cd $(CrankDir)
        chmod +x ./run.sh
        ./run.sh "linux" "$(runExtendedThroughputTests)"
      displayName: Crank tracer
      env:
        DD_SERVICE: dd-trace-dotnet
        DD_ENV: CI
        DD_CIVISIBILITY_AGENTLESS_ENABLED: true
        DD_API_KEY: $(ddApiKey)

    - script: |
        mkdir -p $(CrankDir)/results
        cp $(CrankDir)/*.json $(CrankDir)/results
      displayName: Copy the results to results dir
      condition: succeededOrFailed()
      continueOnError: true

    - publish: "$(CrankDir)/results"
      displayName: Publish results
      artifact: crank_linux_x64_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

  - job: Windows64
    timeoutInMinutes: 60

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download windows native binary
      inputs:
        artifact: windows-tracer-home
        path: $(System.DefaultWorkingDirectory)/tracer/tracer-home-win

    - script: |
        test ! -s "tracer/tracer-home-win/win-x64/Datadog.Trace.ClrProfiler.Native.dll" && echo "tracer/tracer-home-win/win-x64/Datadog.Trace.ClrProfiler.Native.dll (native loader) does not exist" && exit 1
        test ! -s "tracer/tracer-home-win/win-x64/Datadog.Tracer.Native.dll" && echo "tracer/tracer-home-win/win-x64/Datadog.Tracer.Native.dll does not exist" && exit 1
        test ! -s "tracer/tracer-home-win/win-x64/ddwaf.dll" && echo "tracer/tracer-home-win/win-x64/ddwaf.dll does not exist" && exit 1
        mkdir -p tracer/bin/netcoreapp3.1
        cp tracer/tracer-home-win/netcoreapp3.1/Datadog.Trace.dll tracer/bin/netcoreapp3.1/Datadog.Trace.dll 
        cd $(CrankDir)
        chmod +x ./run.sh
        ./run.sh "windows" "$(runExtendedThroughputTests)"
      displayName: Crank tracer
      env:
        DD_SERVICE: dd-trace-dotnet
        DD_ENV: CI
        DD_CIVISIBILITY_AGENTLESS_ENABLED: true
        DD_API_KEY: $(ddApiKey)

    - script: |
        mkdir -p $(CrankDir)/results
        cp $(CrankDir)/*.json $(CrankDir)/results
      displayName: Copy the results to results dir
      condition: succeededOrFailed()
      continueOnError: true

    - publish: "$(CrankDir)/results"
      displayName: Publish results
      artifact: crank_windows_x64_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

  - job: LinuxArm64
    timeoutInMinutes: 60

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - task: DownloadPipelineArtifact@2
      displayName: Download arm64 native binary
      inputs:
        artifact: linux-monitoring-home-arm64
        path: $(System.DefaultWorkingDirectory)/tracer/tracer-home-linux-arm64

    - script: |
        test ! -s "tracer/tracer-home-linux-arm64/linux-arm64/Datadog.Trace.ClrProfiler.Native.so" && echo "tracer/tracer-home-linux-arm64/linux-arm64/Datadog.Trace.ClrProfiler.Native.so (native loader) does not exist" && exit 1
        test ! -s "tracer/tracer-home-linux-arm64/linux-arm64/Datadog.Tracer.Native.so" && echo "tracer/tracer-home-linux-arm64/linux-arm64/Datadog.Tracer.Native.so does not exist" && exit 1
        test ! -s "tracer/tracer-home-linux-arm64/linux-arm64/libddwaf.so" && echo "tracer/tracer-home-linux-arm64/linux-arm64/libddwaf.so does not exist" && exit 1
        mkdir -p tracer/bin/netcoreapp3.1
        cp tracer/tracer-home-linux-arm64/netcoreapp3.1/Datadog.Trace.dll tracer/bin/netcoreapp3.1/Datadog.Trace.dll 
        cd $(System.DefaultWorkingDirectory)/tracer/build/crank
        chmod +x ./run.sh
        ./run.sh "linux_arm64" "$(runExtendedThroughputTests)"
      displayName: Crank
      env:
        DD_SERVICE: dd-trace-dotnet
        DD_ENV: CI
        DD_CIVISIBILITY_AGENTLESS_ENABLED: true
        DD_API_KEY: $(ddApiKey)

    - script: |
        mkdir -p $(CrankDir)/results
        cp $(CrankDir)/*.json $(CrankDir)/results
      displayName: Copy the results to results dir
      condition: succeededOrFailed()
      continueOnError: true

    - publish: "$(CrankDir)/results"
      displayName: Publish results
      artifact: crank_linux_arm64_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

- stage: throughput_profiler
  condition: > 
    and(
      succeeded(), 
      ne(variables['isNgenTestBuild'], 'True'),
      eq(variables.isMainRepository, true),
      eq(dependencies.generate_variables.outputs['generate_variables_job.generate_variables_step.IsProfilerChanged'], 'True')
    )
  dependsOn: [package_linux, generate_variables, build_windows_tracer, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
    crankDir: $(System.DefaultWorkingDirectory)/profiler/build/crank
  pool: Throughput-profiler
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Linux64, Windows64]
  #### Throughput Linux 64, windows 64, linux arm 64

  - job: Linux64
    timeoutInMinutes: 60

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download linux native binary
      inputs:
        artifact: linux-monitoring-home-centos7
        path: $(System.DefaultWorkingDirectory)/monitoring-home-linux

    - script: |
        test ! -s "monitoring-home-linux/linux-x64/Datadog.Trace.ClrProfiler.Native.so" && echo "monitoring-home-linux/linux-x64/Datadog.Trace.ClrProfiler.Native.so (native loader) does not exist" && exit 1
        test ! -s "monitoring-home-linux/linux-x64/Datadog.Tracer.Native.so" && echo "monitoring-home-linux/linux-x64/Datadog.Tracer.Native.so does not exist" && exit 1
        test ! -s "monitoring-home-linux/linux-x64/libddwaf.so" && echo "monitoring-home-linux/linux-x64/libddwaf.so does not exist" && exit 1
        cd $(crankDir)
        chmod +x ./run.sh
        ./run.sh "linux"
      displayName: Crank profiler
      env:
        DD_SERVICE: dd-trace-dotnet-profiler
        DD_ENV: CI
        DD_CIVISIBILITY_AGENTLESS_ENABLED: true
        DD_API_KEY: $(ddApiKey)

    - script: |
        mkdir -p $(crankDir)/results
        cp $(crankDir)/*.json $(crankDir)/results
      displayName: Copy the results to results dir
      condition: succeededOrFailed()
      continueOnError: true

    - publish: "$(crankDir)/results"
      displayName: Publish results
      artifact: crank_profiler_linux_x64_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

  - job: Windows64
    timeoutInMinutes: 60

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download windows native binary
      inputs:
        artifact: windows-tracer-home
        path: $(System.DefaultWorkingDirectory)/monitoring-home-windows

    - script: |
        test ! -s "monitoring-home-windows/win-x64/Datadog.Trace.ClrProfiler.Native.dll" && echo "monitoring-home-windows/win-x64/Datadog.Trace.ClrProfiler.Native.dll does not exist" && exit 1
        test ! -s "monitoring-home-windows/win-x64/ddwaf.dll" && echo "monitoring-home-windows/win-x64/ddwaf.dll does not exist" && exit 1
        cd $(crankDir)
        chmod +x ./run.sh
        ./run.sh "windows"
      displayName: Crank profiler

      env:
        DD_SERVICE: dd-trace-dotnet-profiler
        DD_ENV: CI
        DD_CIVISIBILITY_AGENTLESS_ENABLED: true
        DD_API_KEY: $(ddApiKey)

    - script: |
        mkdir -p $(crankDir)/results
        cp $(crankDir)/*.json $(crankDir)/results
      displayName: Copy the results to results dir
      condition: succeededOrFailed()
      continueOnError: true

    - publish: "$(crankDir)/results"
      displayName: Publish results
      artifact: crank_profiler_windows64_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

- stage: throughput_appsec
  condition: and(succeeded(), eq(variables.isMainRepository, true))
  dependsOn: [package_linux, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
    CrankDir: $(System.DefaultWorkingDirectory)/tracer/build/crank
  pool: Throughput-AppSec
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Linux64]
  #### Throughput-AppSec Linux 64

  - job: Linux64
    timeoutInMinutes: 60

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - task: DownloadPipelineArtifact@2
      displayName: Download linux native binary
      inputs:
        artifact: linux-monitoring-home-centos7
        path: $(System.DefaultWorkingDirectory)/tracer/tracer-home-linux

    - script: |
        test ! -s "tracer/tracer-home-linux/linux-x64/Datadog.Trace.ClrProfiler.Native.so" && echo "tracer/tracer-home-linux/linux-x64/Datadog.Trace.ClrProfiler.Native.so (native loader) does not exist" && exit 1
        test ! -s "tracer/tracer-home-linux/linux-x64/Datadog.Tracer.Native.so" && echo "tracer/tracer-home-linux/linux-x64/Datadog.Tracer.Native.so does not exist" && exit 1
        test ! -s "tracer/tracer-home-linux/linux-x64/libddwaf.so" && echo "tracer/tracer-home-linux/linux-x64/libddwaf.so does not exist" && exit 1
        cd $(CrankDir)
        chmod +x ./run-appsec.sh
        ./run-appsec.sh "linux"
      displayName: Crank
      env:
        DD_SERVICE: dd-trace-dotnet
        DD_ENV: CI

    - script: |
        mkdir -p $(CrankDir)/results
        cp $(CrankDir)/*.json $(CrankDir)/results
      displayName: Copy the results to results dir
      condition: succeededOrFailed()
      continueOnError: true

    - publish: "$(CrankDir)/results"
      displayName: Publish results
      artifact: crank_linux_x64_asm_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

- stage: coverage
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn:
    - integration_tests_windows
    - integration_tests_windows_iis
    - integration_tests_windows_iis_security
    - integration_tests_azure_functions
    - msi_integration_tests_windows
    - integration_tests_linux
    - integration_tests_arm64
    - unit_tests_linux
    - unit_tests_macos
    - unit_tests_arm64
    - unit_tests_windows
    - master_commit_id
    - tool_artifacts_tests_windows
    - tool_artifacts_tests_linux
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
    - job: Windows
      timeoutInMinutes: 30

      pool:
        vmImage: windows-2022

      steps:
      - template: steps/clone-repo.yml
        parameters:
          masterCommitId: $(masterCommitId)
      - template: steps/install-latest-dotnet-sdk.yml

      - task: DownloadPipelineArtifact@2
        inputs:
          patterns: '**/coverage.cobertura.xml'
          path: $(Build.SourcesDirectory)/cover

      - task: reportgenerator@4
        inputs:
          reports: '$(Build.SourcesDirectory)\cover\**\coverage.cobertura.xml'
          targetdir: '$(Build.SourcesDirectory)\coveragereport'
          sourcedirs: '$(Build.SourcesDirectory);..'
          reporttypes: 'Cobertura'

      - task: PublishCodeCoverageResults@1
        inputs:
          codeCoverageTool: 'Cobertura'
          summaryFileLocation: '$(Build.SourcesDirectory)/coveragereport/Cobertura.xml'
          pathToSources: '$(Build.SourcesDirectory)'

      - script: tracer\build.cmd CompareCodeCoverageReports
        displayName: Compare code coverage
        condition: and(succeeded(), eq(variables.isPullRequest, true))
        env:
          PR_NUMBER: $(System.PullRequest.PullRequestNumber)
          AZURE_DEVOPS_TOKEN: $(AZURE_DEVOPS_TOKEN)
          GITHUB_TOKEN: $(GITHUB_TOKEN)

- stage: execution_benchmarks
  condition: and(succeeded(), eq(variables.isMainRepository, true))
  dependsOn: [build_windows_tracer, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [Windows, compare]

  - job: Windows
    strategy:
      matrix:
        HttpMessageHandler:
          sampleName: HttpMessageHandler
          poolName: ExecBenchAgent1
        FakeDbCommand:
          sampleName: FakeDbCommand
          poolName: ExecBenchAgent2
    pool:
      name: $(poolName)
    timeoutInMinutes: 30 #default value

    # These VMs have the Datadog Agent installed directly, as they don't run docker, and timeit doesn't support agentless yet

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - template: steps/install-dotnet-sdks.yml
    - template: steps/restore-working-directory.yml

    - task: DownloadPipelineArtifact@2
      displayName: Download windows native binary
      inputs:
        artifact: windows-tracer-home
        path: $(monitoringHome)
      retryCountOnTaskFailure: 5

    - task: DotNetCoreCLI@2
      inputs:
        command: 'build'
        arguments: '-c Release'
        workingDirectory: $(System.DefaultWorkingDirectory)/tracer/test/test-applications/integrations/Samples.$(sampleName)
      displayName: 'dotnet build Release $(sampleName)'

    - task: GoTool@0
      displayName: 'Install Go 1.16'
      inputs:
        version: '1.16'
        GOPATH: $(Agent.TempDirectory)
      retryCountOnTaskFailure: 5

    - task: Go@0
      displayName: 'Install timeit tool'
      inputs:
        command: 'install'
        arguments: 'github.com/tonyredondo/timeit@latest'
        workingDirectory: $(System.DefaultWorkingDirectory)
      retryCountOnTaskFailure: 5

    - script: run.cmd
      workingDirectory: $(System.DefaultWorkingDirectory)/tracer/build/timeit/Samples.$(sampleName)
      displayName: Execute Samples.$(sampleName) benchmark
      env:
        DD_SERVICE: dd-trace-dotnet
        DD_ENV: CI

    - powershell: |
        mkdir -p $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks
        cp $(System.DefaultWorkingDirectory)/tracer/build/timeit/Samples.$(sampleName)/results_*.json $(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks
      displayName: Copy the results to benchmarks dir
      condition: succeededOrFailed()
      continueOnError: true

    - publish: "$(System.DefaultWorkingDirectory)/tracer/build_data/benchmarks"
      displayName: Publish results
      artifact: execution_time_benchmarks_windows_x64_$(sampleName)_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - task: PowerShell@2
      displayName: Wait 20 seconds to agent flush before finishing pipeline
      inputs:
        targetType: 'inline'
        script: 'Start-Sleep -s 20'

  - job: compare
    timeoutInMinutes: 60 #default value
    dependsOn: [Windows]
    pool:
      vmImage: windows-2022

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-latest-dotnet-sdk.yml

    - task: DownloadPipelineArtifact@2
      displayName: Download HttpMessageHandler
      inputs:
        artifact: execution_time_benchmarks_windows_x64_HttpMessageHandler_1 #only download the first lot, ignores retries
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/execution_benchmarks/current/execution_time_benchmarks_windows_x64_HttpMessageHandler_1

    - task: DownloadPipelineArtifact@2
      displayName: Download FakeDbCommand
      inputs:
        artifact: execution_time_benchmarks_windows_x64_FakeDbCommand_1 #only download the first lot, ignores retries
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/execution_benchmarks/current/execution_time_benchmarks_windows_x64_FakeDbCommand_1

    - script: tracer\build.cmd CompareExecutionTimeBenchmarkResults
      displayName: Compare execution-time results
      env:
        PR_NUMBER: $(System.PullRequest.PullRequestNumber)
        AZURE_DEVOPS_TOKEN: $(AZURE_DEVOPS_TOKEN)
        GITHUB_TOKEN: $(GITHUB_TOKEN)

    - publish: $(System.DefaultWorkingDirectory)/tracer/build_data/execution_benchmarks/execution_time_report.md
      displayName: Upload report
      artifact: execution_time_report

- stage: system_tests
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_linux, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [test]

  - job: test
    timeoutInMinutes: 60 #default value
    pool:
      vmImage: ubuntu-20.04

    strategy:
      matrix:
        poc:
          WEBLOG_VARIANT: "poc"
        uds:
          WEBLOG_VARIANT: "uds"

    steps:
      - checkout: none
      - script: git clone --depth 1 https://github.com/DataDog/system-tests.git
        displayName: Get system tests repo

      - task: DownloadPipelineArtifact@2
        displayName: Download linux-packages
        inputs:
          artifact: linux-packages-centos7
          patterns: '**/*tar.gz'
          path: $(Build.ArtifactStagingDirectory)

      - script: |
          PACKAGE_NAME=$(basename $(Build.ArtifactStagingDirectory)/datadog-dotnet-apm-*.tar.gz)
          echo Moving $PACKAGE_NAME to system-tests/binaries
          mv $(Build.ArtifactStagingDirectory)/$PACKAGE_NAME system-tests/binaries/
        displayName: Move dotnet binary to system test folder
      - script: ./build.sh dotnet
        workingDirectory: system-tests
        displayName: Build images

      - script: ./run.sh
        workingDirectory: system-tests
        displayName: Run tests
        env:
          DD_API_KEY: $(SYSTEM_TESTS_DD_API_KEY)

      - script: ./run.sh REMOTE_CONFIG_MOCKED_BACKEND_LIVE_DEBUGGING
        workingDirectory: system-tests
        displayName: Run RCM tests
        env:
          DD_API_KEY: $(SYSTEM_TESTS_DD_API_KEY)

      - script: |
          mkdir -p all_logs
          cp -r ./logs* ./all_logs
        workingDirectory: system-tests
        condition: always()
        displayName: Group logs

      - publish: system-tests/all_logs/
        condition: always()
        displayName: System tests logs
        artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)

      - script: |
          cd parametric
          pip install wheel
          pip install -r requirements.txt
          ./run.sh
        workingDirectory: system-tests
        displayName: Run parametric tests
        env:
          DD_API_KEY: $(SYSTEM_TESTS_DD_API_KEY)
          CLIENTS_ENABLED: dotnet

- stage: installer_smoke_tests
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_linux, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [linux]

  - job: linux
    timeoutInMinutes: 45 # should take ~5 mins
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.installer_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: ubuntu-20.04

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)
    - task: DownloadPipelineArtifact@2
      displayName: Download artifacts to smoke test directory
      inputs:
        artifact: $(linuxArtifacts)
        path: $(smokeTestAppDir)/artifacts

    - script: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
      displayName: create test data directories

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg INSTALL_CMD="$(installCmd)" \
          smoke-tests
      env:
        dockerTag: $(dockerTag)
        DD_LOGGER_DD_API_KEY: $(ddApiKey)
      displayName: docker-compose build smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'smoke-tests'
        snapshotPrefix: "smoke_test"

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: alpine
        command: "CheckSmokeTestsForErrors"
        apikey: $(DD_LOGGER_DD_API_KEY)

- stage: nuget_installer_smoke_tests
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [linux]

  - job: linux
    timeoutInMinutes: 45 # should take ~5 mins
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.nuget_installer_linux_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: ubuntu-20.04

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download bundle nuget
      inputs:
        artifact: bundle-nuget-package
        path: $(smokeTestAppDir)/artifacts

    - task: DownloadPipelineArtifact@2
      displayName: Download Datadog.Trace package
      inputs:
        artifact: nuget-packages
        path: $(smokeTestAppDir)/artifacts

    - script: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
      displayName: create test data directories

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg RELATIVE_PROFILER_PATH="$(relativeProfilerPath)" \
          --build-arg RELATIVE_APIWRAPPER_PATH="$(relativeApiWrapperPath)" \
          nuget-smoke-tests
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build nuget-smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'nuget-smoke-tests'
        snapshotPrefix: "smoke_test"

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: alpine
        command: "CheckSmokeTestsForErrors"

- stage: dotnet_tool_nuget_smoke_tests_linux
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [linux]

  - job: linux
    timeoutInMinutes: 45 # should take ~5 mins
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.dotnet_tool_nuget_installer_linux_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: ubuntu-20.04

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download tool runner-dotnet-tool
      inputs:
        artifact: runner-dotnet-tool
        path: $(smokeTestAppDir)/artifacts

    - script: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
      displayName: create test data directories

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          dotnet-tool-nuget-smoke-tests
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build  dotnet-tool-nuget-smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'dotnet-tool-nuget-smoke-tests'
        snapshotPrefix: "smoke_test"

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: alpine
        command: "CheckSmokeTestsForErrors"

- stage: dotnet_tool_smoke_tests_linux
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [linux]

  - job: linux
    timeoutInMinutes: 45 # should take ~5 mins
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.dotnet_tool_installer_linux_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: ubuntu-20.04

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download tool runner-standalone-$(platformSuffix)
      inputs:
        artifact: runner-standalone-$(platformSuffix)
        patterns: "*.tar.gz"
        path: $(Agent.TempDirectory)

    - script: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
        mkdir -p $(smokeTestAppDir)/artifacts
        tar -xf $(Agent.TempDirectory)/dd-trace-$(platformSuffix).tar.gz -C $(smokeTestAppDir)/artifacts
        chmod +x $(smokeTestAppDir)/artifacts/dd-trace
      displayName: create test data directories and extract tool

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          dotnet-tool-smoke-tests
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'dotnet-tool-smoke-tests'
        snapshotPrefix: "smoke_test"

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: alpine
        command: "CheckSmokeTestsForErrors"

- stage: dotnet_tool_self_instrument_smoke_tests_linux
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [linux]

  - job: linux
    timeoutInMinutes: 45 # should take ~5 mins
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
      publishFramework: net6.0
      platformSuffix: linux-x64
      dockerTag: debian_net6
      runtimeImage: "mcr.microsoft.com/dotnet/aspnet:6.0-bullseye-slim"
      installCmd: "dpkg -i ./datadog-dotnet-apm*_amd64.deb"
      linuxArtifacts: "linux-packages-centos7"
    pool:
      vmImage: ubuntu-20.04

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download artifacts to smoke test directory
      inputs:
        artifact: $(linuxArtifacts)
        path: $(smokeTestAppDir)/artifacts

    - task: DownloadPipelineArtifact@2
      displayName: Download tool runner-standalone-$(platformSuffix)
      inputs:
        artifact: runner-standalone-$(platformSuffix)
        patterns: "*.tar.gz"
        path: $(Agent.TempDirectory)

    - script: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
        tar -xf $(Agent.TempDirectory)/dd-trace-$(platformSuffix).tar.gz -C $(smokeTestAppDir)/artifacts
        chmod +x $(smokeTestAppDir)/artifacts/dd-trace
      displayName: create test data directories and extract tool

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg INSTALL_CMD="$(installCmd)" \
          dotnet-tool-self-instrument-smoke-tests
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build dotnet-tool-self-instrument-smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'dotnet-tool-self-instrument-smoke-tests'
        snapshotPrefix: "smoke_test"

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: alpine
        command: "CheckSmokeTestsForErrors"

- stage: installer_smoke_tests_arm64
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_arm64, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
    - template: steps/update-github-status-jobs.yml
      parameters:
        jobs: [linux]

    - job: linux
      timeoutInMinutes: 45 # should take ~15 mins
      strategy:
        matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.installer_smoke_tests_arm64_matrix'] ]
      variables:
        smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
      pool:
        name: aws-arm64-auto-scaling

      steps:
        - task: DownloadPipelineArtifact@2
          displayName: Download artifacts to smoke test directory
          inputs:
            artifact: $(linuxArtifacts)
            path: $(smokeTestAppDir)/artifacts

        - script: |
            mkdir -p tracer/build_data/snapshots
            mkdir -p tracer/build_data/logs
          displayName: create test data directories

        - script: |
            docker-compose -p ddtrace_$(Build.BuildNumber) build \
              --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
              --build-arg RUNTIME_IMAGE=$(runtimeImage) \
              --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
              --build-arg INSTALL_CMD="$(installCmd)" \
              smoke-tests
          env:
            dockerTag: $(dockerTag)
          displayName: docker-compose build smoke-tests
          retryCountOnTaskFailure: 3

        - template: steps/run-snapshot-test.yml
          parameters:
            target: 'smoke-tests'
            snapshotPrefix: "smoke_test"

        - publish: tracer/build_data
          artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
          condition: succeededOrFailed()
          continueOnError: true

        - template: steps/run-in-docker.yml
          parameters:
            build: true
            baseImage: debian
            command: "CheckSmokeTestsForErrors"

- stage: nuget_installer_smoke_tests_arm64
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [linux]

  - job: linux
    timeoutInMinutes: 45 # should take ~15 mins
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.nuget_installer_linux_smoke_tests_arm64_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      name: aws-arm64-auto-scaling

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download bundle nuget
      inputs:
        artifact: bundle-nuget-package
        path: $(smokeTestAppDir)/artifacts

    - task: DownloadPipelineArtifact@2
      displayName: Download Datadog.Trace package
      inputs:
        artifact: nuget-packages
        path: $(smokeTestAppDir)/artifacts

    - script: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
      displayName: create test data directories

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg RELATIVE_PROFILER_PATH="$(relativeProfilerPath)" \
          nuget-smoke-tests
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build nuget-smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'nuget-smoke-tests'
        snapshotPrefix: "smoke_test"

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: debian
        command: "CheckSmokeTestsForErrors"

- stage: dotnet_tool_smoke_tests_arm64
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [linux]

  - job: linux
    timeoutInMinutes: 45 # should take ~15 mins
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.dotnet_tool_installer_smoke_tests_arm64_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      name: aws-arm64-auto-scaling

    steps:
    - task: DownloadPipelineArtifact@2
      displayName: Download dotnet tool
      inputs:
        artifact: runner-standalone-$(platformSuffix)
        patterns: "*.tar.gz"
        path: $(Agent.TempDirectory)

    - script: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
        mkdir -p $(smokeTestAppDir)/artifacts
        tar -xf $(Agent.TempDirectory)/dd-trace-$(platformSuffix).tar.gz -C $(smokeTestAppDir)/artifacts
        chmod +x $(smokeTestAppDir)/artifacts/dd-trace
      displayName: create test data directories and extract tool

    - script: |
        docker-compose -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          dotnet-tool-smoke-tests
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'dotnet-tool-smoke-tests'
        snapshotPrefix: "smoke_test"

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/run-in-docker.yml
      parameters:
        build: true
        baseImage: debian
        command: "CheckSmokeTestsForErrors"

- stage: nuget_installer_smoke_tests_windows
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [windows]

  - job: windows
    timeoutInMinutes: 45 # should take ~15 mins as large Windows docker files
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.nuget_installer_windows_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: windows-2022

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download bundle nuget
      inputs:
        artifact: bundle-nuget-package
        path: $(smokeTestAppDir)/artifacts

    - task: DownloadPipelineArtifact@2
      displayName: Download Datadog.Trace package
      inputs:
        artifact: nuget-packages
        path: $(smokeTestAppDir)/artifacts

    - powershell: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
      displayName: create test data directories

    - bash: |
        docker-compose -f docker-compose.windows.yml -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg CHANNEL_32_BIT="$(channel32Bit)" \
          --build-arg RELATIVE_PROFILER_PATH="$(relativeProfilerPath)" \
          nuget-smoke-tests.windows
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'nuget-smoke-tests.windows'
        snapshotPrefix: "smoke_test"
        isLinux: false

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/install-latest-dotnet-sdk.yml
    - script: tracer\build.cmd CheckSmokeTestsForErrors
      displayName: CheckSmokeTestsForErrors

- stage: dotnet_tool_smoke_tests_windows
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [dotnet_tool, package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [windows]

  - job: windows
    timeoutInMinutes: 45 # should take ~15 mins as large Windows docker files
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.dotnet_tool_installer_windows_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: windows-2022

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download dotnet tool
      inputs:
        artifact: runner-standalone-win-x64
        patterns: "dd-trace-win-x64.zip"
        path: $(Agent.TempDirectory)

    - powershell: |
        mkdir -f -p tracer/build_data/snapshots
        mkdir -f -p tracer/build_data/logs
        mkdir -f -p $(smokeTestAppDir)/artifacts
        mv $(Agent.TempDirectory)/*.zip $(smokeTestAppDir)/artifacts/dd-trace-win.zip
      displayName: Create test data directories

    - bash: |
        docker-compose -f docker-compose.windows.yml -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg CHANNEL_32_BIT="$(channel32Bit)" \
          dotnet-tool-smoke-tests.windows
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'dotnet-tool-smoke-tests.windows'
        snapshotPrefix: "smoke_test"
        isLinux: false

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/install-latest-dotnet-sdk.yml
    - script: tracer\build.cmd CheckSmokeTestsForErrors
      displayName: CheckSmokeTestsForErrors

- stage: msi_installer_smoke_tests
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'), or(eq(variables.isMainOrReleaseBranch, 'true'), eq(variables.run_all_installer_tests, 'true')))
  dependsOn: [package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [windows]

  - job: windows
    timeoutInMinutes: 45 # should take ~15 mins as large Windows docker files
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.msi_installer_windows_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: windows-2022

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - task: DownloadPipelineArtifact@2
      displayName: Download MSI to temp directory
      inputs:
        artifact: windows-msi-$(targetPlatform)
        patterns: '**/*-$(targetPlatform).msi'
        path: $(Agent.TempDirectory)

    - powershell: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
        mkdir -p $(smokeTestAppDir)/artifacts
        mv $(Agent.TempDirectory)/*.msi $(smokeTestAppDir)/artifacts/datadog-apm.msi
      displayName: Create test data directories

    - bash: |
        docker-compose -f docker-compose.windows.yml -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg CHANNEL_32_BIT="$(channel32Bit)" \
          smoke-tests.windows
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'smoke-tests.windows'
        snapshotPrefix: "smoke_test"
        isLinux: false

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/install-latest-dotnet-sdk.yml
    - script: tracer\build.cmd CheckSmokeTestsForErrors
      displayName: CheckSmokeTestsForErrors

- stage: tracer_home_smoke_tests
  condition: and(succeeded(), eq(variables['isBenchmarksOnlyBuild'], 'False'))
  dependsOn: [package_windows, generate_variables, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - template: steps/update-github-status-jobs.yml
    parameters:
      jobs: [windows]

  - job: windows
    timeoutInMinutes: 45 # should take ~15 mins as large Windows docker files
    strategy:
      matrix: $[ stageDependencies.generate_variables.generate_variables_job.outputs['generate_variables_step.tracer_home_installer_windows_smoke_tests_matrix'] ]
    variables:
      smokeTestAppDir: "$(System.DefaultWorkingDirectory)/tracer/test/test-applications/regression/AspNetCoreSmokeTest"
    pool:
      vmImage: windows-2022

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - powershell: |
        mkdir -p tracer/build_data/snapshots
        mkdir -p tracer/build_data/logs
        mkdir -p $(smokeTestAppDir)/artifacts
      displayName: Create test data directories

    - task: DownloadPipelineArtifact@2
      displayName: Download tracer home zip
      inputs:
        artifact: windows-tracer-home.zip
        path: $(smokeTestAppDir)/artifacts

    - bash: |
        docker-compose -f docker-compose.windows.yml -p ddtrace_$(Build.BuildNumber) build \
          --build-arg DOTNETSDK_VERSION=$(dotnetCoreSdkLatestVersion) \
          --build-arg RUNTIME_IMAGE=$(runtimeImage) \
          --build-arg PUBLISH_FRAMEWORK=$(publishFramework) \
          --build-arg CHANNEL_32_BIT="$(channel32Bit)" \
          --build-arg RELATIVE_PROFILER_PATH="$(relativeProfilerPath)" \
          tracer-home-smoke-tests.windows
      env:
        dockerTag: $(dockerTag)
      displayName: docker-compose build smoke-tests
      retryCountOnTaskFailure: 3

    - template: steps/run-snapshot-test.yml
      parameters:
        target: 'tracer-home-smoke-tests.windows'
        snapshotPrefix: "smoke_test"
        isLinux: false

    - publish: tracer/build_data
      artifact: _$(System.StageName)_$(Agent.JobName)_logs_$(System.JobAttempt)
      condition: succeededOrFailed()
      continueOnError: true

    - template: steps/install-latest-dotnet-sdk.yml
    - script: tracer\build.cmd CheckSmokeTestsForErrors
      displayName: CheckSmokeTestsForErrors

- stage: compare_throughput
  condition: and(succeeded(), eq(variables.isMainRepository, true))
  dependsOn: [throughput, throughput_appsec, master_commit_id]
  variables:
    masterCommitId: $[ stageDependencies.master_commit_id.fetch.outputs['set_sha.master']]
  jobs:
  - job: compare
    timeoutInMinutes: 60 #default value
    pool:
      vmImage: windows-2022

    steps:
    - template: steps/clone-repo.yml
      parameters:
        masterCommitId: $(masterCommitId)

    - template: steps/install-latest-dotnet-sdk.yml

    - task: DownloadPipelineArtifact@2
      displayName: Download crank_linux_arm64_1
      inputs:
        artifact: crank_linux_arm64_1 #only download the first lot, ignores retries
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/throughput/current/crank_linux_arm64_1

    - task: DownloadPipelineArtifact@2
      displayName: Download crank_linux_x64_1
      inputs:
        artifact: crank_linux_x64_1 #only download the first lot, ignores retries
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/throughput/current/crank_linux_x64_1

    - task: DownloadPipelineArtifact@2
      displayName: Download crank_linux_x64_asm_1
      inputs:
        artifact: crank_linux_x64_asm_1 #only download the first lot, ignores retries
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/throughput/current/crank_linux_x64_asm_1

    - task: DownloadPipelineArtifact@2
      displayName: Download crank_windows_x64_1
      inputs:
        artifact: crank_windows_x64_1 #only download the first lot, ignores retries
        path: $(System.DefaultWorkingDirectory)/tracer/build_data/throughput/current/crank_windows_x64_1

    - script: tracer\build.cmd CompareThroughputResults
      displayName: Compare Crank results
      env:
        PR_NUMBER: $(System.PullRequest.PullRequestNumber)
        AZURE_DEVOPS_TOKEN: $(AZURE_DEVOPS_TOKEN)
        GITHUB_TOKEN: $(GITHUB_TOKEN)

    - publish: $(System.DefaultWorkingDirectory)/tracer/build_data/throughput/throughput_report.md
      displayName: Upload report
      artifact: crank_throughput_report

- stage: trace_pipeline
  condition: eq(variables['isBenchmarksOnlyBuild'], 'False')
  dependsOn:
    - master_commit_id
    - unit_tests_linux
    - unit_tests_macos
    - unit_tests_windows
    - unit_tests_arm64
    - integration_tests_windows
    - integration_tests_windows_debugger
    - integration_tests_windows_iis
    - integration_tests_windows_iis_security
    - integration_tests_azure_functions
    - msi_integration_tests_windows
    - integration_tests_linux
    - integration_tests_linux_debugger
    - integration_tests_arm64
    - integration_tests_arm64_debugger
    - profiler_integration_tests_linux
    - profiler_integration_tests_windows
    - exploration_tests_windows
    - exploration_tests_linux
    - benchmarks
    - throughput
    - throughput_appsec
    - tool_artifacts_tests_windows
    - tool_artifacts_tests_linux
    - upload_to_s3
    - upload_to_azure
    - upload_container_images
    - execution_benchmarks
    - installer_smoke_tests
    - installer_smoke_tests_arm64
    - nuget_installer_smoke_tests
    - nuget_installer_smoke_tests_arm64
    - nuget_installer_smoke_tests_windows
    - dotnet_tool_nuget_smoke_tests_linux
    - dotnet_tool_smoke_tests_linux
    - dotnet_tool_self_instrument_smoke_tests_linux
    - dotnet_tool_smoke_tests_arm64
    - dotnet_tool_smoke_tests_windows
    - msi_installer_smoke_tests
    - tracer_home_smoke_tests
    - coverage
    - compare_throughput
    - system_tests
  jobs:
  - job: build_and_run
    timeoutInMinutes: 60 #default value

    pool:
      vmImage: ubuntu-20.04

    services:
      dd_agent: dd_agent

    steps:
    - template: steps/install-latest-dotnet-sdk.yml
    - bash: dotnet run $(Build.BuildId)
      displayName: "Run"
      workingDirectory: "$(Build.SourcesDirectory)/tracer/tools/PipelineMonitor"

    - bash: sleep 20
      displayName: Wait 20 seconds to agent flush before finishing pipeline

- stage: notify_slack_on_failures
  condition: >
    and(
      failed(),
      eq(variables['isBenchmarksOnlyBuild'], 'False'),
      eq(variables['isMainBranch'], true)
    )
  dependsOn: trace_pipeline # so it runs last
  jobs:
  - job: notify
    timeoutInMinutes: 10
    pool:
      vmImage: ubuntu-20.04

    steps:
    - bash: |
        sha=$(echo $(OriginalCommitId) | head -c 7)
        curl -X POST \
        -H "Content-Type: application/json" \
        -d '{"commit": "'$sha'"}' \
          $(slackWebhookUrl)
      displayName: "notify"
